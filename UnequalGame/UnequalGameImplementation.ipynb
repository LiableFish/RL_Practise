{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "UnequalGameImplementation.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7CyocjBJ1SP",
        "colab_type": "text"
      },
      "source": [
        "## Unequal Game solution with CCEM method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AABSYH3vJ1SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cZE6eLK2MdR",
        "colab_type": "text"
      },
      "source": [
        "# Calculating optimal guaranteed results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9eLwv6LY4xn",
        "colab_type": "text"
      },
      "source": [
        "Let's find guaranteed results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKfpwnUFMYsK",
        "colab_type": "text"
      },
      "source": [
        "Definitions\n",
        "\n",
        "\\begin{gather*}\n",
        "\\Gamma^u = \\min_{u(\\cdot)}\\max_{v(\\cdot)} \\gamma(u,\\, v), \\quad \n",
        "\\Gamma^v = \\max_{v(\\cdot)}\\min_{u(\\cdot)} \\gamma(u,\\, v), \\\\\n",
        "\\tilde{\\Gamma}^u = \\min_{u(\\cdot,\\, \\cdot)}\\max_{v(\\cdot,\\, \\cdot)} \\gamma(u, v), \\quad \n",
        "\\tilde{\\Gamma}^v = \\max_{v(\\cdot,\\, \\cdot)}\\min_{u(\\cdot,\\, \\cdot)} \\gamma(u, v), \\\\\\\\\n",
        "\\Gamma^v \\leqslant \\tilde{\\Gamma}^v \\leqslant  \\tilde{\\Gamma}^v \\leqslant \\Gamma^u.\n",
        "\\end{gather*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjyRmxcvY_pQ",
        "colab_type": "text"
      },
      "source": [
        "Our differential game model\n",
        "\n",
        "\\begin{gather*}\n",
        "\\begin{cases}\n",
        "\\dot{x} = u(t,\\,x) - v(t,\\,x), \\quad t \\in [0, 2],\\\\\n",
        "x(0) = 1, \\\\\n",
        "|u| \\leqslant 2, \\quad |v| \\leqslant 1.\n",
        "\\end{cases}, \\\\ \\\\\n",
        "\\gamma(u,\\, v) = x^2(2) = \\left(1 + \\int\\limits_0^2 u(t, x)\\,dt - \\int\\limits_0^2 v(t, x)\\,dt \\right)^2 = (1 +U(x) + V(x))^2, \\\\|U| \\leqslant 4, \\quad |V| \\leqslant 2, \\\\ \\\\\n",
        "\\Gamma^u = 4, \\quad \\Gamma^v = \\tilde{\\Gamma}^v = \\tilde{\\Gamma}^v = 0.\n",
        "\\end{gather*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAd2UkykbgJ0",
        "colab_type": "text"
      },
      "source": [
        "Compute $\\Gamma^u$\n",
        "\n",
        "\\begin{gather*}\n",
        "\\max_V \\gamma(U,\\, V) = \\max\\left\\{\\gamma(U,\\, 2),\\, \\gamma(U,\\, -2)\\right\\}, \\\\ \\\\\n",
        "\\gamma(U, 2) - \\gamma(U, -2) = -8(1+U).\n",
        "\\end{gather*}\n",
        "\n",
        "Case 1:\n",
        "\\begin{gather*}\n",
        "\\max_V \\gamma(U,\\, V) = \\gamma(U,\\, 2) \\; \\Longrightarrow \\; U \\leqslant -1 \\; \\Longrightarrow \\; \\Gamma^u = \\min_U \\gamma(U\\,2) = \\gamma(-1, 2) = 4.\n",
        "\\end{gather*}\n",
        "\n",
        "Case 2:\n",
        "\\begin{gather*}\n",
        "\\max_V \\gamma(U,\\, V) = \\gamma(U,\\, -2) \\; \\Longrightarrow \\; U \\geqslant -1 \\; \\Longrightarrow \\; \\Gamma^u = \\min_U \\gamma(U\\,-2) = \\gamma(-1, -2) = 4.\n",
        "\\end{gather*}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4J4HcicfuGC",
        "colab_type": "text"
      },
      "source": [
        "Compute $\\Gamma^v$\n",
        "\n",
        "\\begin{gather*}\n",
        "\\frac{\\partial}{\\partial U} \\gamma(U,\\,V) = 2(1 + U - V) = 0 \\;\\Longrightarrow\\; U = V - 1 \\Longrightarrow\\; \\Gamma^v = \\max_{V}\\gamma(V-1,\\,V) = 0\n",
        "\\end{gather*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20rbj4TTllV8",
        "colab_type": "text"
      },
      "source": [
        "Compute $\\tilde{\\Gamma}^u$\n",
        "\n",
        "\\begin{gather*}\n",
        "\\forall U, V \\quad \\tilde{\\Gamma}^u \\geqslant 0, \\\\ \\\\\n",
        "U(x) = - 4 \\cdot \\text{sign}(x) \\;\\Longrightarrow\\; \\gamma(U,\\, V) = \\max_{V}(1 - 4 \\cdot \\text{sign}(x) - V(x))^2\n",
        "\\end{gather*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhvN61Hitl5J",
        "colab_type": "text"
      },
      "source": [
        "Compute $\\tilde{\\Gamma}^v$\n",
        "\n",
        "\\begin{gather*}\n",
        "0 = \\Gamma^v \\leqslant \\tilde{\\Gamma}^v \\leqslant \\tilde{\\Gamma}^u = 0 \\; \\Longrightarrow \\; \\tilde{\\Gamma}^v = 0.\n",
        "\\end{gather*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKQpP3ao2VR6",
        "colab_type": "text"
      },
      "source": [
        "# Code implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5YRCc2MJ1SU",
        "colab_type": "text"
      },
      "source": [
        "Implement environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj46-jGRJ1SV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UnequalGame:\n",
        "\n",
        "    def __init__(self, initial_x=1, dt=0.005, terminal_time=2, u_action_max=2, v_action_max=1):\n",
        "        self.u_action_max = u_action_max\n",
        "        self.v_action_max = v_action_max\n",
        "        self.terminal_time = terminal_time\n",
        "        self.dt = dt\n",
        "        self.initial_x = initial_x\n",
        "        self.state = self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.array([0, self.initial_x])\n",
        "        return self.state\n",
        "\n",
        "    def step(self, u_action, v_action):\n",
        "        t, x = self.state\n",
        "        x = x + (u_action - v_action) * self.dt\n",
        "        t += self.dt\n",
        "        self.state = np.array([t, x])\n",
        "\n",
        "        reward = 0\n",
        "        done = False\n",
        "        if t >= self.terminal_time:\n",
        "            reward = x ** 2\n",
        "            done = True\n",
        "\n",
        "        return self.state, reward, done, None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01OM_i5PJ1SX",
        "colab_type": "text"
      },
      "source": [
        "Implement agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S80KcE1J1SY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_shape, output_shape):\n",
        "        super().__init__()\n",
        "        self.linear_1 = torch.nn.Linear(input_shape[0], 50)\n",
        "        self.linear_2 = torch.nn.Linear(50, 30)\n",
        "        self.linear_3 = torch.nn.Linear(30, output_shape[0])\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.tang = torch.nn.Tanh()\n",
        "\n",
        "    def forward(self, input_):\n",
        "        hidden = self.relu(self.linear_1(input_))\n",
        "        hidden = self.relu(self.linear_2(hidden))\n",
        "        output = self.tang(self.linear_3(hidden))\n",
        "        return output\n",
        "\n",
        "\n",
        "class CCEMAgent(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, state_shape, action_shape, action_max, reward_param=1, percentile_param=70, noise_decrease=0.98,\n",
        "                 tau=1e-2, learning_rate=1e-2, n_learning_per_fit=16):\n",
        "        super().__init__()\n",
        "        self.action_max = np.abs(action_max)\n",
        "        self.reward_param = reward_param  # equal to 1 if agent wants to maximize reward otherwise -1\n",
        "        self.percentile_param = percentile_param\n",
        "        self.noise_decrease = noise_decrease\n",
        "        self.noise_threshold = 1\n",
        "        self.min_noise_threshold = 0.1\n",
        "        self.tau = tau\n",
        "        self.n_learning_per_fit = n_learning_per_fit\n",
        "        self.network = Network(state_shape, action_shape)\n",
        "        self.optimizer = torch.optim.Adam(params=self.network.parameters(), lr=learning_rate)\n",
        "\n",
        "    def get_action(self, state, test=False):\n",
        "        state = torch.FloatTensor(state)\n",
        "        predicted_action = self.network(state).detach().numpy() * self.action_max\n",
        "        if not test:\n",
        "            noise = self.noise_threshold * np.random.uniform(low=-self.action_max, high=self.action_max)\n",
        "            predicted_action = np.clip(predicted_action + noise, -self.action_max, self.action_max)\n",
        "        return predicted_action\n",
        "\n",
        "    def get_elite_states_and_actions(self, sessions):\n",
        "        \"\"\"\n",
        "          Select sessions with the most or least reward\n",
        "          by percentile\n",
        "        \"\"\"\n",
        "        total_rewards = [session['total_reward'] for session in sessions]\n",
        "        reward_threshold = np.percentile(total_rewards, self.percentile_param)\n",
        "\n",
        "        elite_states = []\n",
        "        elite_actions = []\n",
        "        for session in sessions:\n",
        "            if self.reward_param * (session['total_reward'] - reward_threshold) > 0:\n",
        "                elite_states.extend(session['states'])\n",
        "                elite_actions.extend(session[f'{self}actions'])\n",
        "\n",
        "        return torch.FloatTensor(elite_states), torch.FloatTensor(elite_actions)\n",
        "\n",
        "    def learn_network(self, loss):\n",
        "        self.optimizer.zero_grad()\n",
        "        old_network = deepcopy(self.network)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        for new_parameter, old_parameter in zip(self.network.parameters(), old_network.parameters()):\n",
        "            new_parameter.data.copy_(self.tau * new_parameter + (1 - self.tau) * old_parameter)\n",
        "\n",
        "        return None\n",
        "\n",
        "    def fit(self, sessions):\n",
        "        elite_states, elite_actions = self.get_elite_states_and_actions(sessions)\n",
        "\n",
        "        for _ in range(self.n_learning_per_fit):\n",
        "            predicted_action = self.network(elite_states) * self.action_max\n",
        "            loss = torch.mean((predicted_action - elite_actions) ** 2)\n",
        "            self.learn_network(loss)\n",
        "\n",
        "        if self.noise_threshold > self.min_noise_threshold:\n",
        "            self.noise_threshold *= self.noise_decrease\n",
        "\n",
        "        return None\n",
        "\n",
        "    def __str__(self):\n",
        "        return 'u_' if self.reward_param == -1 else 'v_'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzV4HKqsJ1Sb",
        "colab_type": "text"
      },
      "source": [
        "Fit agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrjBLPuDJ1Sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_session(u_agent, v_agent, env, test=False):\n",
        "    \"\"\"\n",
        "    Generate session on environment with agent\n",
        "    \"\"\"\n",
        "    states = []\n",
        "    u_actions = []\n",
        "    v_actions = []\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    state = env.reset()\n",
        "    while not done:\n",
        "        u_action = u_agent.get_action(state, test=test)\n",
        "        v_action = v_agent.get_action(state)\n",
        "        actions = (u_action[0], v_action[0]) if str(u_agent) == 'u_' else (v_action[0], u_action[0])\n",
        "        next_state, reward, done, _ = env.step(*actions)\n",
        "        states.append(state)\n",
        "        u_actions.append(u_action)\n",
        "        v_actions.append(v_action)\n",
        "        total_reward += reward\n",
        "        state = next_state\n",
        "\n",
        "    return {'states': states, f'{u_agent}actions': u_actions, f'{v_agent}actions': v_actions, 'total_reward': total_reward}\n",
        "\n",
        "def fit_epoch(u_agent, v_agent, env, n_sessions, test):\n",
        "    sessions = [generate_session(u_agent, v_agent, env, test=test) for _ in range(n_sessions)]\n",
        "    mean_reward = np.mean([session['total_reward'] for session in sessions])\n",
        "    if not test:\n",
        "        u_agent.fit(sessions)\n",
        "    v_agent.fit(sessions)\n",
        "    return mean_reward\n",
        "\n",
        "def fit_agents(u_agent, v_agent, env, n_epochs, n_sessions, epsilon, test=False):\n",
        "    last_mean_reward = 0\n",
        "    mean_rewards = []\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        mean_reward = fit_epoch(u_agent, v_agent, env, n_sessions, test)\n",
        "        mean_rewards.append(mean_reward)\n",
        "        print(f'epoch: {epoch}, mean reward: {mean_reward}')\n",
        "        if np.abs(last_mean_reward - mean_reward) < epsilon:\n",
        "            break\n",
        "        last_mean_reward = mean_reward\n",
        "        \n",
        "    return u_agent, np.array(mean_rewards)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts0iEOAPwNbf",
        "colab_type": "text"
      },
      "source": [
        "Fit agents one by one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zWWu0hLwXVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_agents_one_by_one(u_agent, v_agent, env, n_epochs, n_sessions, n_iter_for_fit, epsilon):\n",
        "    last_mean_reward = 0\n",
        "    mean_rewards = []\n",
        "    fit_agent = u_agent\n",
        "    wait_agent = v_agent\n",
        "    epoch = 0\n",
        "    stop = False\n",
        "\n",
        "    while not stop and epoch < n_epochs:\n",
        "\n",
        "        for _ in range(n_iter_for_fit):\n",
        "            mean_reward = fit_epoch(wait_agent, fit_agent, env, n_sessions, test=True)\n",
        "            mean_rewards.append(mean_reward)\n",
        "            print(f'epoch: {epoch}, current agent: {fit_agent}, mean reward: {mean_reward}')\n",
        "            if np.abs(last_mean_reward - mean_reward) < epsilon:\n",
        "                stop = True\n",
        "                break\n",
        "            last_mean_reward = mean_reward\n",
        "            epoch += 1\n",
        "\n",
        "        print('\\n')\n",
        "        wait_agent, fit_agent = fit_agent, wait_agent\n",
        "\n",
        "    return u_agent, np.array(mean_rewards)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wR_cLRa2r7A",
        "colab_type": "text"
      },
      "source": [
        "Plot mean rewards by epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI2rrGrK2w6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_mean_rewards(mean_rewards, method_name):\n",
        "    _, ax = plt.subplots(figsize=(10, 8))\n",
        "    ax.plot(range(len(mean_rewards)), mean_rewards, '--')\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.set_ylabel('Mean reward')\n",
        "    ax.set_title(f'Mean rewards for {method_name} over epochs')\n",
        "    plt.show()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgUptSYv2FIK",
        "colab_type": "text"
      },
      "source": [
        "# Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXE4PAqKJ1Se",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = UnequalGame()\n",
        "u_agent = CCEMAgent((2,), (1,), percentile_param=30, action_max=env.u_action_max, reward_param=-1)\n",
        "v_agent = CCEMAgent((2,), (1,), percentile_param=70, action_max=env.v_action_max, reward_param=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDwDnGJD5qa9",
        "colab_type": "text"
      },
      "source": [
        "Deafualt fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IB5KIRc2J1Sg",
        "colab_type": "code",
        "outputId": "7c948d70-de2a-46a2-90b3-179ea16da2d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "u_fit_agent, mean_rewards = fit_agents(u_agent, v_agent, env, n_epochs=100, n_sessions=100, epsilon=1e-6)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, mean reward: 5.8145152667289155\n",
            "epoch: 1, mean reward: 4.653778002830878\n",
            "epoch: 2, mean reward: 3.708761241209931\n",
            "epoch: 3, mean reward: 3.006094615373949\n",
            "epoch: 4, mean reward: 2.43565816206942\n",
            "epoch: 5, mean reward: 1.9608094902435769\n",
            "epoch: 6, mean reward: 1.6014459248892678\n",
            "epoch: 7, mean reward: 1.2900711928099964\n",
            "epoch: 8, mean reward: 1.1132223039508702\n",
            "epoch: 9, mean reward: 0.859408993011087\n",
            "epoch: 10, mean reward: 0.7281587002047512\n",
            "epoch: 11, mean reward: 0.6090404942781238\n",
            "epoch: 12, mean reward: 0.49557114642111016\n",
            "epoch: 13, mean reward: 0.3809047322967401\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-176c0bb8546a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mu_fit_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_agents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-7afcdfac80d5>\u001b[0m in \u001b[0;36mfit_agents\u001b[0;34m(u_agent, v_agent, env, n_epochs, n_sessions, epsilon, test)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mmean_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch: {epoch}, mean reward: {mean_reward}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-7afcdfac80d5>\u001b[0m in \u001b[0;36mfit_epoch\u001b[0;34m(u_agent, v_agent, env, n_sessions, test)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_reward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-7afcdfac80d5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_reward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-7afcdfac80d5>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(u_agent, v_agent, env, test)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mu_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mv_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'u_'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ca55eef9851f>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state, test)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mpredicted_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_threshold\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mpredicted_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_action\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredicted_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDn0VPMmJ1Sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_mean_rewards(mean_rewards, method_name='fit')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsIq2Y3V5njb",
        "colab_type": "text"
      },
      "source": [
        "Fit one by one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW1QxXVg6gYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u_agent_one_by_one = CCEMAgent((2,), (1,), percentile_param=30, action_max=env.u_action_max, reward_param=-1)\n",
        "v_agent_one_by_one = CCEMAgent((2,), (1,), percentile_param=70, action_max=env.v_action_max, reward_param=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo2hX83F6UxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u_fit_agent_one_by_one, mean_rewards_one_by_one =\\\n",
        "fit_agents_one_by_one(u_agent_one_by_one, v_agent_one_by_one, env, \\\n",
        "                       n_epochs=200, n_sessions=100, n_iter_for_fit=20, epsilon=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnAuA95963EE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_mean_rewards(mean_rewards_one_by_one, method_name='fit one by one')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9PYm_lX2h-H",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrkkxFDSJ1Sn",
        "colab_type": "text"
      },
      "source": [
        "Test default u_agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJe3A4XBJ1Sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v_test_agent = CCEMAgent((2,), (1,), percentile_param=70, action_max=env.v_action_max, reward_param=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzC4Sb2QJ1Sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_rewards = fit_agents(u_fit_agent, v_test_agent, env, n_epochs=200, n_sessions=100, epsilon=1e-6, test=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7ZITn34J1Ss",
        "colab_type": "code",
        "outputId": "e0ef7f04-d64f-484f-a2fc-b59bb844e574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plot_mean_rewards(test_rewards, method_name='test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aR-GlF-f0Yg",
        "colab_type": "text"
      },
      "source": [
        "Test u_agent_one_by_one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq_ApuAW7J2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v_test_agent_one_by_one = CCEMAgent((2,), (1,), percentile_param=70, action_max=env.v_action_max, reward_param=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZorei8v7Np4",
        "colab_type": "code",
        "outputId": "05276469-27b3-44ae-ef13-4220821be371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        }
      },
      "source": [
        "test_rewards_one_by_one = fit_agents(u_fit_agent_one_by_one, v_test_agent_one_by_one, env, n_epochs=200, n_sessions=100, epsilon=1e-6, test=True)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, mean reward: 0.29935330500371793\n",
            "epoch: 1, mean reward: 0.3463195958874706\n",
            "epoch: 2, mean reward: 0.39863377134074357\n",
            "epoch: 3, mean reward: 0.44876386878657115\n",
            "epoch: 4, mean reward: 0.5184301819703512\n",
            "epoch: 5, mean reward: 0.5675803224043944\n",
            "epoch: 6, mean reward: 0.6610956458685066\n",
            "epoch: 7, mean reward: 0.719155189885328\n",
            "epoch: 8, mean reward: 0.8087606505324639\n",
            "epoch: 9, mean reward: 0.8731894475197334\n",
            "epoch: 10, mean reward: 0.9641466156679247\n",
            "epoch: 11, mean reward: 1.0607806306994574\n",
            "epoch: 12, mean reward: 1.1459211699883491\n",
            "epoch: 13, mean reward: 1.2403617884670455\n",
            "epoch: 14, mean reward: 1.3314569663243745\n",
            "epoch: 15, mean reward: 1.4291255777865677\n",
            "epoch: 16, mean reward: 1.5161451882285306\n",
            "epoch: 17, mean reward: 1.6060396605848188\n",
            "epoch: 18, mean reward: 1.6833928983433097\n",
            "epoch: 19, mean reward: 1.7653048351406104\n",
            "epoch: 20, mean reward: 1.854041587135409\n",
            "epoch: 21, mean reward: 1.9094481676088035\n",
            "epoch: 22, mean reward: 1.9879866293483772\n",
            "epoch: 23, mean reward: 2.0639365039607975\n",
            "epoch: 24, mean reward: 2.1344752549729695\n",
            "epoch: 25, mean reward: 2.2357074832586683\n",
            "epoch: 26, mean reward: 2.3079804392028054\n",
            "epoch: 27, mean reward: 2.3936350045617107\n",
            "epoch: 28, mean reward: 2.4443979147463395\n",
            "epoch: 29, mean reward: 2.5164225651268164\n",
            "epoch: 30, mean reward: 2.5601826816722446\n",
            "epoch: 31, mean reward: 2.609971272541979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-707c85f7fc87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_rewards_one_by_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_agents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_fit_agent_one_by_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_test_agent_one_by_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-7afcdfac80d5>\u001b[0m in \u001b[0;36mfit_agents\u001b[0;34m(u_agent, v_agent, env, n_epochs, n_sessions, epsilon, test)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mmean_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch: {epoch}, mean reward: {mean_reward}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-7afcdfac80d5>\u001b[0m in \u001b[0;36mfit_epoch\u001b[0;34m(u_agent, v_agent, env, n_sessions, test)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_reward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-7afcdfac80d5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_reward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-7afcdfac80d5>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(u_agent, v_agent, env, test)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mu_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mv_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'u_'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-ca55eef9851f>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state, test)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mpredicted_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_threshold\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-ca55eef9851f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXK3jgOj7QN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_mean_rewards(test_rewards_one_by_one, method_name='test one by one')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpSO6-P_2zfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}