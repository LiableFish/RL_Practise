{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "UnequalGameImplementation.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7CyocjBJ1SP",
        "colab_type": "text"
      },
      "source": [
        "## Unequal Game solution with CCEM method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AABSYH3vJ1SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cZE6eLK2MdR",
        "colab_type": "text"
      },
      "source": [
        "# Calculating optimal guaranteed results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9eLwv6LY4xn",
        "colab_type": "text"
      },
      "source": [
        "Let's find guaranteed results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKfpwnUFMYsK",
        "colab_type": "text"
      },
      "source": [
        "Definitions\n",
        "\n",
        "\\begin{gather*}\n",
        "\\Gamma^u = \\min_{u(\\cdot)}\\max_{v(\\cdot)} \\gamma(u,\\, v), \\quad \n",
        "\\Gamma^v = \\max_{v(\\cdot)}\\min_{u(\\cdot)} \\gamma(u,\\, v), \\\\\n",
        "\\tilde{\\Gamma}^u = \\min_{u(\\cdot,\\, \\cdot)}\\max_{v(\\cdot,\\, \\cdot)} \\gamma(u, v), \\quad \n",
        "\\tilde{\\Gamma}^v = \\max_{v(\\cdot,\\, \\cdot)}\\min_{u(\\cdot,\\, \\cdot)} \\gamma(u, v), \\\\\\\\\n",
        "\\Gamma^v \\leqslant \\tilde{\\Gamma}^v \\leqslant  \\tilde{\\Gamma}^v \\leqslant \\Gamma^u.\n",
        "\\end{gather*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjyRmxcvY_pQ",
        "colab_type": "text"
      },
      "source": [
        "Our differential game model\n",
        "\n",
        "\\begin{gather*}\n",
        "\\begin{cases}\n",
        "\\dot{x} = u(t,\\,x) - v(t,\\,x), \\quad t \\in [0, 2],\\\\\n",
        "x(0) = 1, \\\\\n",
        "|u| \\leqslant 2, \\quad |v| \\leqslant 1.\n",
        "\\end{cases}, \\\\ \\\\\n",
        "\\gamma(u,\\, v) = x^2(2) = \\left(1 + \\int\\limits_0^2 u(t, x)\\,dt - \\int\\limits_0^2 v(t, x)\\,dt \\right)^2 = (1 +U(x) + V(x))^2, \\\\|U| \\leqslant 4, \\quad |V| \\leqslant 2, \\\\ \\\\\n",
        "\\Gamma^u = 4, \\quad \\Gamma^v = \\tilde{\\Gamma}^v = \\tilde{\\Gamma}^v = 0.\n",
        "\\end{gather*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAd2UkykbgJ0",
        "colab_type": "text"
      },
      "source": [
        "Compute $\\Gamma^u$\n",
        "\n",
        "\\begin{gather*}\n",
        "\\max_V \\gamma(U,\\, V) = \\max\\left\\{\\gamma(U,\\, 2),\\, \\gamma(U,\\, -2)\\right\\}, \\\\ \\\\\n",
        "\\gamma(U, 2) - \\gamma(U, -2) = -8(1+U).\n",
        "\\end{gather*}\n",
        "\n",
        "Case 1:\n",
        "\\begin{gather*}\n",
        "\\max_V \\gamma(U,\\, V) = \\gamma(U,\\, 2) \\; \\Longrightarrow \\; U \\leqslant -1 \\; \\Longrightarrow \\; \\Gamma^u = \\min_U \\gamma(U\\,2) = \\gamma(-1, 2) = 4.\n",
        "\\end{gather*}\n",
        "\n",
        "Case 2:\n",
        "\\begin{gather*}\n",
        "\\max_V \\gamma(U,\\, V) = \\gamma(U,\\, -2) \\; \\Longrightarrow \\; U \\geqslant -1 \\; \\Longrightarrow \\; \\Gamma^u = \\min_U \\gamma(U\\,-2) = \\gamma(-1, -2) = 4.\n",
        "\\end{gather*}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4J4HcicfuGC",
        "colab_type": "text"
      },
      "source": [
        "Compute $\\Gamma^v$\n",
        "\n",
        "\\begin{gather*}\n",
        "\\frac{\\partial}{\\partial U} \\gamma(U,\\,V) = 2(1 + U - V) = 0 \\;\\Longrightarrow\\; U = V - 1 \\Longrightarrow\\; \\Gamma^v = \\max_{V}\\gamma(V-1,\\,V) = 0\n",
        "\\end{gather*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20rbj4TTllV8",
        "colab_type": "text"
      },
      "source": [
        "Compute $\\tilde{\\Gamma}^u$\n",
        "\n",
        "\\begin{gather*}\n",
        "\\forall U, V \\quad \\tilde{\\Gamma}^u \\geqslant 0, \\\\ \\\\\n",
        "U(x) = - 4 \\cdot \\text{sign}(x) \\;\\Longrightarrow\\; \\gamma(U,\\, V) = \\max_{V}(1 - 4 \\cdot \\text{sign}(x) - V(x))^2\n",
        "\\end{gather*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhvN61Hitl5J",
        "colab_type": "text"
      },
      "source": [
        "Compute $\\tilde{\\Gamma}^v$\n",
        "\n",
        "\\begin{gather*}\n",
        "0 = \\Gamma^v \\leqslant \\tilde{\\Gamma}^v \\leqslant \\tilde{\\Gamma}^u = 0 \\; \\Longrightarrow \\; \\tilde{\\Gamma}^v = 0.\n",
        "\\end{gather*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKQpP3ao2VR6",
        "colab_type": "text"
      },
      "source": [
        "# Code implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5YRCc2MJ1SU",
        "colab_type": "text"
      },
      "source": [
        "## Implement environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj46-jGRJ1SV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UnequalGame:\n",
        "\n",
        "    def __init__(self, initial_x=1, dt=0.005, terminal_time=2, u_action_max=2, v_action_max=1):\n",
        "        self.u_action_max = u_action_max\n",
        "        self.v_action_max = v_action_max\n",
        "        self.terminal_time = terminal_time\n",
        "        self.dt = dt\n",
        "        self.initial_x = initial_x\n",
        "        self.state = self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.array([0, self.initial_x])\n",
        "        return self.state\n",
        "\n",
        "    def step(self, u_action, v_action):\n",
        "        t, x = self.state\n",
        "        x = x + (u_action - v_action) * self.dt\n",
        "        t += self.dt\n",
        "        self.state = np.array([t, x])\n",
        "\n",
        "        reward = 0\n",
        "        done = False\n",
        "        if t >= self.terminal_time:\n",
        "            reward = x ** 2\n",
        "            done = True\n",
        "\n",
        "        return self.state, reward, done, None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01OM_i5PJ1SX",
        "colab_type": "text"
      },
      "source": [
        "## Implement agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S80KcE1J1SY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_shape, output_shape):\n",
        "        super().__init__()\n",
        "        self.linear_1 = torch.nn.Linear(input_shape[0], 50)\n",
        "        self.linear_2 = torch.nn.Linear(50, 30)\n",
        "        self.linear_3 = torch.nn.Linear(30, output_shape[0])\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.tang = torch.nn.Tanh()\n",
        "\n",
        "    def forward(self, input_):\n",
        "        hidden = self.relu(self.linear_1(input_))\n",
        "        hidden = self.relu(self.linear_2(hidden))\n",
        "        output = self.tang(self.linear_3(hidden))\n",
        "        return output\n",
        "\n",
        "\n",
        "class CCEMAgent(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, state_shape, action_shape, action_max, reward_param=1, percentile_param=70, noise_decrease=0.98,\n",
        "                 tau=1e-2, learning_rate=1e-2, n_learning_per_fit=16):\n",
        "        super().__init__()\n",
        "        self.action_max = np.abs(action_max)\n",
        "        self.reward_param = reward_param  # equal to 1 if agent wants to maximize reward otherwise -1\n",
        "        self.percentile_param = percentile_param\n",
        "        self.noise_decrease = noise_decrease\n",
        "        self.noise_threshold = 1\n",
        "        self.min_noise_threshold = 0.1\n",
        "        self.tau = tau\n",
        "        self.n_learning_per_fit = n_learning_per_fit\n",
        "        self.network = Network(state_shape, action_shape)\n",
        "        self.optimizer = torch.optim.Adam(params=self.network.parameters(), lr=learning_rate)\n",
        "\n",
        "    def get_action(self, state, test=False):\n",
        "        state = torch.FloatTensor(state)\n",
        "        predicted_action = self.network(state).detach().numpy() * self.action_max\n",
        "        if not test:\n",
        "            noise = self.noise_threshold * np.random.uniform(low=-self.action_max, high=self.action_max)\n",
        "            predicted_action = np.clip(predicted_action + noise, -self.action_max, self.action_max)\n",
        "        return predicted_action\n",
        "\n",
        "    def get_elite_states_and_actions(self, sessions):\n",
        "        \"\"\"\n",
        "          Select sessions with the most or least reward\n",
        "          by percentile\n",
        "        \"\"\"\n",
        "        total_rewards = [session['total_reward'] for session in sessions]\n",
        "        reward_threshold = np.percentile(total_rewards, self.percentile_param)\n",
        "\n",
        "        elite_states = []\n",
        "        elite_actions = []\n",
        "        for session in sessions:\n",
        "            if self.reward_param * (session['total_reward'] - reward_threshold) > 0:\n",
        "                elite_states.extend(session['states'])\n",
        "                elite_actions.extend(session[f'{self}actions'])\n",
        "\n",
        "        return torch.FloatTensor(elite_states), torch.FloatTensor(elite_actions)\n",
        "\n",
        "    def learn_network(self, loss):\n",
        "        self.optimizer.zero_grad()\n",
        "        old_network = deepcopy(self.network)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        for new_parameter, old_parameter in zip(self.network.parameters(), old_network.parameters()):\n",
        "            new_parameter.data.copy_(self.tau * new_parameter + (1 - self.tau) * old_parameter)\n",
        "\n",
        "        return None\n",
        "\n",
        "    def fit(self, sessions):\n",
        "        elite_states, elite_actions = self.get_elite_states_and_actions(sessions)\n",
        "\n",
        "        for _ in range(self.n_learning_per_fit):\n",
        "            predicted_action = self.network(elite_states) * self.action_max\n",
        "            loss = torch.mean((predicted_action - elite_actions) ** 2)\n",
        "            self.learn_network(loss)\n",
        "\n",
        "        if self.noise_threshold > self.min_noise_threshold:\n",
        "            self.noise_threshold *= self.noise_decrease\n",
        "\n",
        "        return None\n",
        "\n",
        "    def __str__(self):\n",
        "        return 'u_' if self.reward_param == -1 else 'v_'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiiiimQO6Sip",
        "colab_type": "text"
      },
      "source": [
        "## Generate sessions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrjBLPuDJ1Sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_session(u_agent, v_agent, env, test=False):\n",
        "    \"\"\"\n",
        "    Generate session on environment with agent\n",
        "    \"\"\"\n",
        "    states = []\n",
        "    u_actions = []\n",
        "    v_actions = []\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    state = env.reset()\n",
        "    while not done:\n",
        "        u_action = u_agent.get_action(state, test=test)\n",
        "        v_action = v_agent.get_action(state)\n",
        "        actions = (u_action[0], v_action[0]) if str(u_agent) == 'u_' else (v_action[0], u_action[0])\n",
        "        next_state, reward, done, _ = env.step(*actions)\n",
        "        states.append(state)\n",
        "        u_actions.append(u_action)\n",
        "        v_actions.append(v_action)\n",
        "        total_reward += reward\n",
        "        state = next_state\n",
        "\n",
        "    return {'states': states, \\\n",
        "            f'{u_agent}actions': u_actions, \\\n",
        "            f'{v_agent}actions': v_actions, \\\n",
        "            'total_reward': total_reward}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAwsBQXn6X_F",
        "colab_type": "text"
      },
      "source": [
        "## Fit one epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK6wNInF6Xad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_epoch(u_agent, v_agent, env, n_sessions, test):\n",
        "    sessions = [generate_session(u_agent, v_agent, env, test=test) for _ in range(n_sessions)]\n",
        "    mean_reward = np.mean([session['total_reward'] for session in sessions])\n",
        "    if not test:\n",
        "        u_agent.fit(sessions)\n",
        "    v_agent.fit(sessions)\n",
        "    return mean_reward\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fTW3tWbHyiu",
        "colab_type": "text"
      },
      "source": [
        "## Test agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUU1ytZhHca5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_agent(u_agent, env, n_epochs, n_sessions, epsilon):\n",
        "    v_agent = CCEMAgent((2,), (1,), percentile_param=70, action_max=env.v_action_max, reward_param=1)\n",
        "    _, rewards = fit_agents(u_agent, v_agent, env, n_epochs, n_sessions, epsilon, test=True)\n",
        "    return rewards"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzV4HKqsJ1Sb",
        "colab_type": "text"
      },
      "source": [
        "## Fit agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY6XooSIHbeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_agents(u_agent, v_agent, env, n_epochs, n_sessions,\\\n",
        "               epsilon, n_iter_debug=0, test=False):\n",
        "    last_mean_reward = 0\n",
        "    mean_rewards = []\n",
        "    epoch = 0\n",
        "\n",
        "    while epoch < n_epochs:\n",
        "\n",
        "        if n_iter_debug and epoch and epoch % n_iter_debug == 0:\n",
        "            print('\\n{:-^50}\\n'.format('TEST BEGIN'))\n",
        "            test_agent(u_agent, env, n_epochs=20, n_sessions=n_sessions, epsilon=epsilon)\n",
        "            print('\\n{:-^50}\\n'.format('TEST END'))\n",
        "        \n",
        "        mean_reward = fit_epoch(u_agent, v_agent, env, n_sessions, test)\n",
        "        mean_rewards.append(mean_reward)\n",
        "        print(f'epoch: {epoch}, mean reward: {mean_reward}')\n",
        "        if np.abs(last_mean_reward - mean_reward) < epsilon:\n",
        "            break\n",
        "        last_mean_reward = mean_reward\n",
        "        epoch += 1\n",
        "\n",
        "        \n",
        "    return u_agent, np.array(mean_rewards)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts0iEOAPwNbf",
        "colab_type": "text"
      },
      "source": [
        "## Fit agents one by one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zWWu0hLwXVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_agents_one_by_one(u_agent, v_agent, env, n_epochs, n_sessions,\\\n",
        "                          n_iter_for_fit, epsilon, n_iter_debug=0):\n",
        "    last_mean_reward = 0\n",
        "    mean_rewards = []\n",
        "    fit_agent = u_agent\n",
        "    wait_agent = v_agent\n",
        "    epoch = 0\n",
        "    stop = False\n",
        "\n",
        "    while not stop and epoch < n_epochs:\n",
        "\n",
        "        for _ in range(n_iter_for_fit):\n",
        "            if n_iter_debug and epoch and epoch % n_iter_debug == 0:\n",
        "                print('\\n{:-^50}\\n'.format('TEST BEGIN'))\n",
        "                test_agent(u_agent, env, n_epochs=20, n_sessions=n_sessions, epsilon=epsilon)\n",
        "                print('\\n{:-^50}\\n'.format('TEST END'))\n",
        "\n",
        "            mean_reward = fit_epoch(wait_agent, fit_agent, env, n_sessions, test=True)\n",
        "            mean_rewards.append(mean_reward)\n",
        "            print(f'epoch: {epoch}, current agent: {fit_agent}, mean reward: {mean_reward}')\n",
        "            if np.abs(last_mean_reward - mean_reward) < epsilon:\n",
        "                stop = True\n",
        "                break\n",
        "            last_mean_reward = mean_reward\n",
        "            epoch += 1\n",
        "            if epoch >= n_epochs:\n",
        "                break\n",
        "\n",
        "        print('\\n')\n",
        "        wait_agent, fit_agent = fit_agent, wait_agent\n",
        "\n",
        "    return u_agent, np.array(mean_rewards)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY5KIG4n5qAi",
        "colab_type": "text"
      },
      "source": [
        "## Fit random agent pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To2h6mLx7cSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_random_agent_pairs(u_agents, v_agents, env, n_pairs, n_epochs, n_sessions, n_iter_debug=0):\n",
        "    u_agents_mean_rewards = [[] for _ in range(len(u_agents))]\n",
        "\n",
        "    for _ in range(n_pairs):\n",
        "        u_agent_idx = np.random.choice(len(u_agents))\n",
        "        v_agent_idx = np.random.choice(len(v_agents))\n",
        "        print('\\n{:-^50}\\n'.format(f'U_AGENT_{u_agent_idx} VS V_AGENT_{v_agent_idx}'))\n",
        "        _, mean_rewards = fit_agents(u_agents[u_agent_idx], v_agents[v_agent_idx],\n",
        "                                     env=env, n_epochs=n_epochs, n_sessions=n_sessions,\n",
        "                                     epsilon=-1, n_iter_debug=n_iter_debug)\n",
        "        print('\\n{:-^50}\\n'.format(''))\n",
        "        u_agents_mean_rewards[u_agent_idx].append(mean_rewards.min())\n",
        "\n",
        "    best_u_agent_idx = np.argmin(np.min(lst) if lst else float('inf') for lst in u_agents_mean_rewards)\n",
        "    print(f'\\nBest agent is {best_u_agent_idx}, its best reward is {np.min(u_agents_mean_rewards[best_u_agent_idx])}\\n')\n",
        "    return u_agents[best_u_agent_idx], u_agents_mean_rewards\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wR_cLRa2r7A",
        "colab_type": "text"
      },
      "source": [
        "## Plot mean rewards by epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI2rrGrK2w6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_mean_rewards(mean_rewards, method_name):\n",
        "    _, ax = plt.subplots(figsize=(10, 8))\n",
        "    ax.plot(range(len(mean_rewards)), mean_rewards, '--')\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.set_ylabel('Mean reward')\n",
        "    ax.set_title(f'Mean rewards for {method_name} over epochs')\n",
        "    plt.show()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgUptSYv2FIK",
        "colab_type": "text"
      },
      "source": [
        "# Fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDwDnGJD5qa9",
        "colab_type": "text"
      },
      "source": [
        "## Deafualt fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXE4PAqKJ1Se",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = UnequalGame()\n",
        "u_agent = CCEMAgent((2,), (1,), percentile_param=30, action_max=env.u_action_max, reward_param=-1)\n",
        "v_agent = CCEMAgent((2,), (1,), percentile_param=70, action_max=env.v_action_max, reward_param=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IB5KIRc2J1Sg",
        "colab_type": "code",
        "outputId": "d85426e1-66a5-417d-854b-81bdf898662c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "u_fit_agent, mean_rewards = fit_agents(u_agent, v_agent, env, n_epochs=101, n_sessions=100, epsilon=1e-6, n_iter_debug=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, mean reward: 1.3773243197560843\n",
            "epoch: 1, mean reward: 1.2849220297923083\n",
            "epoch: 2, mean reward: 1.1776507786345252\n",
            "epoch: 3, mean reward: 1.0594609653392284\n",
            "epoch: 4, mean reward: 0.9349823134704391\n",
            "epoch: 5, mean reward: 0.8492211485084661\n",
            "epoch: 6, mean reward: 0.7407841572648346\n",
            "epoch: 7, mean reward: 0.6469161470111148\n",
            "epoch: 8, mean reward: 0.5104650559918649\n",
            "epoch: 9, mean reward: 0.42697672565390443\n",
            "epoch: 10, mean reward: 0.3406296869713519\n",
            "epoch: 11, mean reward: 0.2848880261093028\n",
            "epoch: 12, mean reward: 0.23680522576171867\n",
            "epoch: 13, mean reward: 0.18388487993362304\n",
            "epoch: 14, mean reward: 0.14299283117802505\n",
            "epoch: 15, mean reward: 0.10584941179520252\n",
            "epoch: 16, mean reward: 0.06968883015453446\n",
            "epoch: 17, mean reward: 0.04056886945767383\n",
            "epoch: 18, mean reward: 0.022133273573165857\n",
            "epoch: 19, mean reward: 0.012398481921391527\n",
            "epoch: 20, mean reward: 0.0060429898070711785\n",
            "epoch: 21, mean reward: 0.002909253841796586\n",
            "epoch: 22, mean reward: 0.0029399799736055192\n",
            "epoch: 23, mean reward: 0.00237278702199119\n",
            "epoch: 24, mean reward: 0.002346423861609727\n",
            "epoch: 25, mean reward: 0.0025778598399387497\n",
            "epoch: 26, mean reward: 0.002176417869540448\n",
            "epoch: 27, mean reward: 0.0021326175533266213\n",
            "epoch: 28, mean reward: 0.0014089926281819099\n",
            "epoch: 29, mean reward: 0.002341789351505363\n",
            "epoch: 30, mean reward: 0.0017896860186720387\n",
            "epoch: 31, mean reward: 0.001836590891026031\n",
            "epoch: 32, mean reward: 0.0016089127091866253\n",
            "epoch: 33, mean reward: 0.001344004768654295\n",
            "epoch: 34, mean reward: 0.0012665036836372941\n",
            "epoch: 35, mean reward: 0.0018250519608096422\n",
            "epoch: 36, mean reward: 0.001514721708301345\n",
            "epoch: 37, mean reward: 0.0015117943124533276\n",
            "epoch: 38, mean reward: 0.001381011027561077\n",
            "epoch: 39, mean reward: 0.001265620337311212\n",
            "epoch: 40, mean reward: 0.0016039120408215654\n",
            "epoch: 41, mean reward: 0.0013418287774921711\n",
            "epoch: 42, mean reward: 0.0009551737941527492\n",
            "epoch: 43, mean reward: 0.0011700335337082063\n",
            "epoch: 44, mean reward: 0.0010775051933935638\n",
            "epoch: 45, mean reward: 0.0011193879487535656\n",
            "epoch: 46, mean reward: 0.0009629906768729652\n",
            "epoch: 47, mean reward: 0.0009573528978890103\n",
            "epoch: 48, mean reward: 0.0009294826328785266\n",
            "epoch: 49, mean reward: 0.0007366058129093774\n",
            "\n",
            "--------------------TEST BEGIN--------------------\n",
            "\n",
            "epoch: 0, mean reward: 0.09289094561186952\n",
            "epoch: 1, mean reward: 0.13302336252340624\n",
            "epoch: 2, mean reward: 0.17713212877870205\n",
            "epoch: 3, mean reward: 0.2273883224129115\n",
            "epoch: 4, mean reward: 0.2814645865248842\n",
            "epoch: 5, mean reward: 0.3425471373804181\n",
            "epoch: 6, mean reward: 0.4126353757980954\n",
            "epoch: 7, mean reward: 0.4916799679847935\n",
            "epoch: 8, mean reward: 0.5703097798604984\n",
            "epoch: 9, mean reward: 0.6449479924989916\n",
            "epoch: 10, mean reward: 0.7282845920891501\n",
            "epoch: 11, mean reward: 0.8064743757841736\n",
            "epoch: 12, mean reward: 0.8762060721787792\n",
            "epoch: 13, mean reward: 0.9515679049431485\n",
            "epoch: 14, mean reward: 1.031034987109545\n",
            "epoch: 15, mean reward: 1.1160804780377647\n",
            "epoch: 16, mean reward: 1.1925333503936972\n",
            "epoch: 17, mean reward: 1.2601371748602472\n",
            "epoch: 18, mean reward: 1.3438910245927587\n",
            "epoch: 19, mean reward: 1.4132209985031698\n",
            "\n",
            "---------------------TEST END---------------------\n",
            "\n",
            "epoch: 50, mean reward: 0.0007792864848654366\n",
            "epoch: 51, mean reward: 0.0006131830254033579\n",
            "epoch: 52, mean reward: 0.0009098939462058312\n",
            "epoch: 53, mean reward: 0.000696830168829788\n",
            "epoch: 54, mean reward: 0.0007173634877250809\n",
            "epoch: 55, mean reward: 0.0006702053192123205\n",
            "epoch: 56, mean reward: 0.0005332154995198315\n",
            "epoch: 57, mean reward: 0.0006709205702569898\n",
            "epoch: 58, mean reward: 0.0006799392949250066\n",
            "epoch: 59, mean reward: 0.0006710885966040288\n",
            "epoch: 60, mean reward: 0.0005154265653780349\n",
            "epoch: 61, mean reward: 0.00042309747266236865\n",
            "epoch: 62, mean reward: 0.0004601663984521849\n",
            "epoch: 63, mean reward: 0.0004425429405308221\n",
            "epoch: 64, mean reward: 0.0004386640493235947\n",
            "epoch: 65, mean reward: 0.00042187743556878365\n",
            "epoch: 66, mean reward: 0.0003496055031852683\n",
            "epoch: 67, mean reward: 0.0005794861339825875\n",
            "epoch: 68, mean reward: 0.0003301519957560288\n",
            "epoch: 69, mean reward: 0.00034204223238222845\n",
            "epoch: 70, mean reward: 0.00030787418559137\n",
            "epoch: 71, mean reward: 0.0004288339095708815\n",
            "epoch: 72, mean reward: 0.0003733272084174898\n",
            "epoch: 73, mean reward: 0.0002607782134972288\n",
            "epoch: 74, mean reward: 0.0002777111113500326\n",
            "epoch: 75, mean reward: 0.00036766731057461346\n",
            "epoch: 76, mean reward: 0.00029795682947578796\n",
            "epoch: 77, mean reward: 0.0002460644603397297\n",
            "epoch: 78, mean reward: 0.00029508075190964146\n",
            "epoch: 79, mean reward: 0.00018033484121999892\n",
            "epoch: 80, mean reward: 0.0002223554346456235\n",
            "epoch: 81, mean reward: 0.0002256313061937255\n",
            "epoch: 82, mean reward: 0.00028173921459274503\n",
            "epoch: 83, mean reward: 0.00020160167854677919\n",
            "epoch: 84, mean reward: 0.00021537058393156038\n",
            "epoch: 85, mean reward: 0.00017569326781569\n",
            "epoch: 86, mean reward: 0.00021574122455943589\n",
            "epoch: 87, mean reward: 0.00017161922109342346\n",
            "epoch: 88, mean reward: 0.00016858880332934093\n",
            "epoch: 89, mean reward: 0.0002060685179733215\n",
            "epoch: 90, mean reward: 0.00012998797315434094\n",
            "epoch: 91, mean reward: 0.0001606730724035577\n",
            "epoch: 92, mean reward: 0.0001372640549510327\n",
            "epoch: 93, mean reward: 0.00011382906853537305\n",
            "epoch: 94, mean reward: 0.00013044445450109294\n",
            "epoch: 95, mean reward: 0.00013055436869872244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDn0VPMmJ1Sk",
        "colab_type": "code",
        "outputId": "78c34124-5e7b-4228-d6ac-04d5c7de69ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "plot_mean_rewards(mean_rewards, method_name='fit')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAHwCAYAAADuJ7gwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd5ycZb338e9vZluSbUl2s0k2vUIqwQVB6QckoIBdEAuK8no8BxHLQR8LIufgUfSxI4ooYAMRCxE4oPRelhJIgJBGetm0Td/s7vyeP+beZHaTbCbJzl5TPu/XK6/szH3PzHfKZr657muuMXcXAAAAelcsdAAAAIBCRAkDAAAIgBIGAAAQACUMAAAgAEoYAABAAJQwAACAAChhAHKGmT1sZp86hMu9x8yWmdlWM5vRAznqzOxRM9tiZv/PzL5qZjce7vXmIzMbZWZuZkWhswDZhl8KIDAze1PSUElD3X1dyvkvSjpK0mh3fzNMurzxfUmXuvudPXR9l0haJ6nSuyy2aGajJC2WVOzubT10ewDyECNhQHZYLOmCjhNmNlVS33Bx9ggxgmFJPfnv00hJcw8xS3w/1/dq1wKWTTLwGALoYfyCAtnhd5I+lnL645J+m7qDmZWa2ffNbKmZrTGzX5hZn2hbfzO7y8yazGxj9POwlMs+bGb/ZWZPRIfQ/mlmNfsKYmanmNlyM/uyma2WdJOZxczsK2a20MzWm9ntZjYg2v8WM/ti9HN9dOjpP6LTY81sQ3T5dDJeY2ZPSNouaYyZnWFmr5tZs5n9TJKl7D/OzB6Jtq0zsz/t476UmtlWSXFJs81sYXT+kdHtbTKzuWZ2bsplbjaz683sHjPbJunULtd5c/T8XBEd3jzdzK4ys99Huzwa/b0p2n78fnL9yMxWRn9+ZGal0bbXzOxdKfsWRY/Z0dHp48zsySj7bDM7pbvHcB+3PdTM/hJd52Izuyxl21VmdoeZ/Sl6nbxgZtNTtnf3uPWx5KHZJdFz8njH6zNyYfTaXWdmX0u53LFm1mhmm6PX9Q+6ZgbyFSUMyA5PS6qM3uTiks6X9Psu+3xH0gQlD1GOk1Qv6cpoW0zSTUqO0IyQtEPSz7pc/sOSPiFpkKQSSV/qJs9gSQOi67tE0mclvVvSyUoeOt0o6bpo30cknRL9fLKkRZJOSjn9mLsn0sz40ej2KiQ1S/qrpK9LqpG0UNLbU/b9L0n/lNRf0jBJP+16J9y9xd3Lo5PT3X2smRVL+kd02UHRffuDmU1MueiHJV0T5Xi8y3VeJOkPkq5193J3v7/LzXbc9+po+1Ndc0n6mqTjlHwup0s6NrqfknSrUkZFJZ0paZ27v2Bm9ZLulvTfSj4/X5L0FzOrTdk/9TFcknqjlhwZ+4ek2Uq+fv5N0uVmdmbKbudJ+nN0/X+U9HczK07jcfu+pLdIelt02SskJVKu9wRJE6PbvNLMjozO/7GkH7t7paSxkm7fx+MF5CVKGJA9OkbDzpD0mqQVHRvMzJR8Y/28u29w9y2Svq1kWZO7r3f3v7j79mjbNUoWoFQ3ufsb7r5DyTe6o7rJkpD0zajE7JD0fyR9zd2Xu3uLpKskvd+ShyofkXRC9AZ/kqRrtacsnRxtTzfjze4+N5pLdZakue5+h7u3SvqRpNUp+7YqWeiGuvtOd39c6TlOUrmk77j7Lnd/UNJd6lx87nT3J9w94e4707zeg3GhpKvdfa27N0n6lpLlSUoWn3PNrONw9IeVLGaS9BFJ97j7PVG2f0lqlHR2ynXvfgyjxy3VMZJq3f3q6L4vkvQrRa+jyPMpj/kPJJUp+Zjt93GLnvtPSvqcu69w93Z3fzJ6rXT4lrvvcPfZSpbAjhG2VknjzKzG3be6+9MH91ACuYsSBmSP3yn5hnuRuhyKlFSr5Byx56NDQZsk3RudLzPra2a/jA4FbVbykFi1dZ7PlFpgtiv5hro/TV3Kx0hJf0u57dcktUuqc/eFkrYpWepOVPKNeWU0QrK7hKWZcVnKz0NTT0fzr1K3X6Hk4clno0Njn+zm/qQaKmlZNDrXYYmSI0P7ypEJQ9V5lGpJdJ7cfYGSj+85URE7V8liJiWfhw90PA/Rc3GCpCFpZh8paWiXy39VUt2+Lh89RsujbN09bjVKlrWF3dz2/l5/Fys5wvu6mT2XeigWyHd8OhLIEu6+xMwWKzmqcXGXzeuUPHw32d1X7HVh6YtKHup5q7uvNrOjJL2olDlUBxuny+llkj7p7k/sZ/9HJL1fUom7rzCzR5ScN9Vf0ksHkTH1dldJGt5xIhoN3H3a3VdL+nS07QRJ95vZo1GJ6c5KScPNLJZSKEZIemM/OQ5WOpddqc4fFhgRndeh45BkTMkPAHTcp2WSfufunz7E218mabG7j+9mn9THPKbkod6ObPt73NZJ2qnk4cTZ3Vz33mHd52vPaNp7Jd1hZgPdfdvBXA+QixgJA7LLxZJO6/oGFL3p/UrSD81skLR7EnzHXJ4KJUvaJktOmP9mD+f6haRrzGxkdNu1ZnZeyvZHJF2qPZPSH45OP+7u7YeY8W5Jk83svdFhz8uUnKumKMMHbM/E/o1Klo/E3lezl2eUHIm5IprrdIqkcyTdlsZl09EU5dhrUnyKWyV9PXoca5Sc25c6B/A2Se+Q9BntGQVTtM85ZnammcXNrMySH6QYpvQ8K2mLJT900Se6jilmdkzKPm9Jecwvl9Si5JzF/T5u0evzN5J+EE38j5vZ8RZ92KA7ZvYRM6uNrmNTdHY6zyOQ8yhhQBZx94Xu3rifzV+WtEDS09HhvPuVHFmSkvOl+ig5IvG0kocqe9KPJc2S9E8z2xLdxltTtj+iZMnqKGGPK3n49NGUfQ4qY7Rm2geU/EDCeknjJaWOxB0j6RlLfvpxlpLzkRYd6I64+y4ly8NZUZafS/qYu79+oMumw923Kznf7YnokN9x+9jtv5Wcy/WypFckvRCd13EdqyQ9peQk9z+lnL9MyYnzX1Wy7C2T9J9K89/yqBC/S8lDx4uVvP83SqpK2e1OSR9Ssth+VNJ73b01jcftS9F9eU7SBknfTTPXTElzo+fxx5LOj+YhAnnPsniZGwBALzKzqySNc/ePhM4CFAJGwgAAAAKghAEAAATA4UgAAIAAGAkDAAAIgBIGAAAQQM4t1lpTU+OjRo0KHQMAAOCAnn/++XXuXruvbTlXwkaNGqXGxv0towQAAJA9zGzJ/rZxOBIAACAAShgAAEAAlDAAAIAAKGEAAAABUMIAAAACoIQBAAAEQAkDAAAIIGMlzMx+Y2ZrzWzOAfY7xszazOz9mcoCAACQbTI5EnazpJnd7WBmcUnflfTPDOYAAADIOhkrYe7+qKQNB9jts5L+ImltpnIAAABko2BzwsysXtJ7JF0fKgMAAEAoISfm/0jSl909caAdzewSM2s0s8ampqZeiAYAAJBZIb/Au0HSbWYmSTWSzjazNnf/e9cd3f0GSTdIUkNDg/dqSgAAgAwIVsLcfXTHz2Z2s6S79lXAAAAA8lHGSpiZ3SrpFEk1ZrZc0jclFUuSu/8iU7cLAACQCzJWwtz9goPY96JM5QAAAMhGrJgPAAAQACWsi52t7br/1TVa2LQ1dBQAAJDHKGFdtCVcn/5do+6avSp0FAAAkMcoYV2UlxZpTE0/vbJiU+goAAAgj1HC9mFqfZVeWdEcOgYAAMhjlLB9mDqsWms2t2jt5p2howAAgDxFCduHqfVVksRoGAAAyJiQX1uUtaYNq9L9XzhJo2vKQ0cBAAB5ihK2D2XFcY0bVBE6BgAAyGMcjtyPpxau13/f9WroGAAAIE9Rwvbj9dWbdePji7WGyfkAACADKGH7MW1YcnL+y8uZnA8AAHoeJWw/Jg2pUsz4hCQAAMgMSth+9CmJa9ygcr2ynJXzAQBAz6OEdWNqfbU2bm8NHQMAAOQhlqjoxnffN1VFcXoqAADoeTSMblDAAABAptAyuuHu+szvn9eNjy0KHQUAAOQZSlg3zEyL123TY/PXhY4CAADyDCXsAKbWV2nOima5e+goAAAgj1DCDmDqsCqt37ZLq5pZOR8AAPQcStgBTK1n5XwAANDzKGEHcOSQSjWM7K/iuIWOAgAA8gjrhB1AWXFcd3zmbaFjAACAPMNIWJra2hNMzgcAAD2GEpaGe15ZpcnfvE8rNu0IHQUAAOQJSlga6qv7qKUtoTkrmJwPAAB6BiUsDRMHV6goZnxCEgAA9BhKWBrKiuMaX1ehuSs3h44CAADyBCUsTUcMrtAba7aEjgEAAPIES1Sk6eypQzS2tp8SCVcsxpphAADg8FDC0nTGpDqdMakudAwAAJAnOBx5ENZvbdHazXyHJAAAOHyUsDS5u0753sP66YMLQkcBAAB5gBKWJjPThMEVmsfkfAAA0AMoYQdhQl2F5q3ewtcXAQCAw0YJOwhHDK5Q845Wrd3SEjoKAADIcZSwgzChrkKSNG81hyQBAMDhoYQdhMn1lbr2/dM0cXBF6CgAACDHsU7YQagsK9YHG4aHjgEAAPIAI2EH6c112/Tg62tCxwAAADmOEnaQfvvUEv37H15Qe4JPSAIAgENHCTtIRwyu0M7WhJZt2B46CgAAyGGUsIM0IZqUz6KtAADgcFDCDtKEunJJLFMBAAAODyXsIPUtKdKIAX0ZCQMAAIeFJSoOwc8vPFqDKktDxwAAADmMEnYIptRXhY4AAAByHIcjD8GazTt1/cML+YQkAAA4ZBkrYWb2GzNba2Zz9rP9QjN72cxeMbMnzWx6prL0tOYdrfruva/r+SUbQ0cBAAA5KpMjYTdLmtnN9sWSTnb3qZL+S9INGczSo0bX9FNx3JicDwAADlnG5oS5+6NmNqqb7U+mnHxa0rBMZelpxfGYxtaW6w2WqQAAAIcoW+aEXSzpf0OHOBgT6ir0OiUMAAAcouAlzMxOVbKEfbmbfS4xs0Yza2xqauq9cN2YOLhCa7fs1PZdbaGjAACAHGTumfsi6uhw5F3uPmU/26dJ+puks9z9jXSus6GhwRsbG3ss46Ha1tKm4nhMJUXBeywAAMhSZva8uzfsa1uwdcLMbISkv0r6aLoFLJv0K2WJNQAAcOgy1iTM7FZJp0iqMbPlkr4pqViS3P0Xkq6UNFDSz81Mktr21xSz1bX3vq7BVWX62PGjQkcBAAA5JpOfjrzgANs/JelTmbr93vDkwvXqUxynhAEAgIPGhKbDMLGugrXCAADAIaGEHYbxdeXasG2XNmzbFToKAADIMZSwwzBuULkkacHarYGTAACAXEMJOwxja8s1uLJMW1taQ0cBAAA5hnUWDsPwAX319Ff/LXQMAACQgxgJAwAACIASdphufGyRPvrrZ0LHAAAAOYYSdpi2trTp8QXrtLO1PXQUAACQQyhhh2lsbbncpcXrtoWOAgAAcggl7DCNrU0uU7GwiWUqAABA+ihhh2lMbT+ZSQvXMhIGAADSRwk7TGXFcb1jUp0GlpeEjgIAAHII64T1gF9+tCF0BAAAkGMYCesh7i53Dx0DAADkCEpYD7h3zipNveqfWr5xR+goAAAgR1DCesCAfqXa2tLGJyQBAEDaKGE9YGxtP0nSgrWUMAAAkB5KWA8Y0K9E1X2LtbCJZSoAAEB6KGE9wMw0rracw5EAACBtLFHRQ949o17bWtpCxwAAADmCEtZDPnLcyNARAABADuFwZA9q3tHKaBgAAEgLJayHLNuwXdO/9U/d/fKq0FEAAEAOoIT1kKHVfVRSFGNyPgAASAslrIfEY6YxNf1YKwwAAKSFEtaDxrJMBQAASBMlrAeNHVSupRu2q6WtPXQUAACQ5ViiogedcWSd6ipLlUiETgIAALIdJawHTR1WpanDqkLHAAAAOYDDkT1s/potTM4HAAAHRAnrYRfd9Jx++uD80DEAAECWo4T1sLGD+IQkAAA4MEpYDxtb208L125TIuGhowAAgCxGCethY2vLtaO1Xas37wwdBQAAZDFKWA8bW1suSUzOBwAA3aKE9bAp9ZX6zUUNmsZSFQAAoBusE9bDKsqKddoRdaFjAACALMdIWAY8v2Sj7p2zOnQMAACQxRgJy4DfPvWmGt/cqJlTBoeOAgAAshQjYRkwuqafVjbv0M5WvsgbAADsGyUsA0bX9JO7tGT99tBRAABAlqKEZUDHMhWL17FMBQAA2DdKWAaMquknSVq0blvgJAAAIFsxMT8DykuLdN/lJ2nEgL6howAAgCxFCcuQiYMrQkcAAABZjMORGfLs4g36/n3zQscAAABZihKWIbOXbdLPHlqgjdt2hY4CAACyECUsQ0ZHk/MXr2dyPgAA2FvGSpiZ/cbM1prZnP1sNzP7iZktMLOXzezoTGUJYUxtVMKaKGEAAGBvmRwJu1nSzG62nyVpfPTnEknXZzBLrxs+oK/iMdNilqkAAAD7kLES5u6PStrQzS7nSfqtJz0tqdrMhmQqT28rjsc0YkBfrWreGToKAADIQiGXqKiXtCzl9PLovFVh4vS8uy87QX1LWAUEAADsLScm5pvZJWbWaGaNTU1NoeOkjQIGAAD2J2QJWyFpeMrpYdF5e3H3G9y9wd0bamtreyVcT3h5+SZ99tYXtXYzhyQBAEBnIUvYLEkfiz4leZykZnfPm0ORkrS1pU3/mL1S89fyRd4AAKCzjB0vM7NbJZ0iqcbMlkv6pqRiSXL3X0i6R9LZkhZI2i7pE5nKEsqYmnJJyS/yfvu4msBpAABANslYCXP3Cw6w3SX9R6ZuPxvUVZaqb0lci5oYCQMAAJ3lxMT8XGVmGl3Tj7XCAADAXihhGTZ5aKWKYjzMAACgM9ZQyLBr3z89dAQAAJCFGKIBAAAIgBKWYcs2bNf7r39Sj7yRO4vMAgCAzKOEZVhln2I1Ltmo11dtDh0FAABkEUpYhlX1KVZNeYkWNfEJSQAAsAclrBewTAUAAOiKEtYLRtf00yJKGAAASMESFb2gYeQArd+6S63tCRXH6b0AAIAS1is+eMxwffCY4aFjAACALMKwTC9Kfl0mAAAAJaxXtCdcJ137kH78wPzQUQAAQJaghPWCeMwkSfPXbA2cBAAAZAtKWC+ZUl+p2cs3hY4BAACyBCWsl8wY3l/LN+5Q05aW0FEAAEAWoIT1khkjqiVJLy1jNAwAAFDCes2U+ipdcOwI1VWWho4CAACyAOuE9ZKy4rj+571TQ8cAAABZgpGwXpRIuOav2aL2BOuFAQBQ6ChhvejO2St0xg8f1YK1LFUBAECho4T1ounDOibnbwycBAAAhEYJ60Wja/qpqk+xXlzKJyQBACh0lLBeZGY6ang1y1QAAABKWG87ani15q3Zoq0tbaGjAACAgFiiopede9RQTRtWpaLo+yQBAEBhooT1srG15RpbWx46BgAACIzDkQHMXrZJ//vKqtAxAABAQJSwAG558k194865cmfRVgAAChUlLIAZI6q1bmuLlm/cEToKAAAIhBIWwFHD+0sSS1UAAFDAKGEBHDGkQqVFMRZtBQCggFHCAiiOxzS1vkqvrKCEAQBQqFiiIpCfXDBDA8tLQscAAACBUMICGVrdJ3QEAAAQEIcjA9nVltA1d7+qe+ewXhgAAIWIEhZISVFMs2av1L1zVoeOAgAAAqCEBTRjeH+9yDIVAAAUJEpYQNOGV2nJ+u1q3tEaOgoAAOhllLCAjhhcIUmav2ZL4CQAAKC3UcICmlBXoZryUm3azkgYAACFhiUqAhrWv68av3566BgAACAARsIAAAACoIQF9odnluj91z8pdw8dBQAA9CJKWGAtrQk1LtmodVt3hY4CAAB6ESUssIl8QhIAgIJECQtsQl2yhM2jhAEAUFAoYYHVlJdoQL8SvUEJAwCgoLBERWBmpplTBmtoVVnoKAAAoBdltISZ2UxJP5YUl3Sju3+ny/YRkm6RVB3t8xV3vyeTmbLRt98zNXQEAADQyzJ2ONLM4pKuk3SWpEmSLjCzSV12+7qk2919hqTzJf08U3mynburPcEyFQAAFIpMzgk7VtICd1/k7rsk3SbpvC77uKTK6OcqSSszmCdrvbpys6Z965969I2m0FEAAEAvyWQJq5e0LOX08ui8VFdJ+oiZLZd0j6TP7uuKzOwSM2s0s8ampvwrKvXVfbRlZxufkAQAoIDst4SZ2YDu/vTQ7V8g6WZ3HybpbEm/M7O9Mrn7De7e4O4NtbW1PXTT2aOqb7EGV5bpjdWUMAAACkV3E/OfV/JwoUkaIWlj9HO1pKWSRh/guldIGp5yelh0XqqLJc2UJHd/yszKJNVIWptm/rwxYXAFI2EAABSQ/Y6Euftodx8j6X5J57h7jbsPlPQuSf9M47qfkzTezEabWYmSE+9nddlnqaR/kyQzO1JSmaT8O96Yhol15VqwdiuT8wEAKBDpLFFxnLt/uuOEu/+vmV17oAu5e5uZXSrpPiWXn/iNu881s6slNbr7LElflPQrM/u8kqNuF3mBfpP1KRMHqaQoppa2dvUtYfk2AADynR2o85jZfZIek/T76KwLJZ3k7mdmONs+NTQ0eGNjY4ibBgAAOChm9ry7N+xrWzqfjrxAUq2kv0n6a/TzBT0XDx22trRp7eadoWMAAIBe0O1xr2jB1Z+6+4W9lKegvfMnj2lKfZWu+/DRoaMAAIAM63YkzN3bJY2MJtYjw8YPqmCZCgAACkQ6M8AXSXrCzGZJ2tZxprv/IGOpCtTEweV6eN5atbS1q7QoHjoOAADIoHTmhC2UdFe0b0XKH/SwCXUVaku4Fq/bduCdAQBATjvgSJi7f6s3gkCaODjZbeet3qIjBlceYG8AAJDLDljCzKxW0hWSJiu5mKokyd1Py2CugjSmplxXnzdZM4b3Dx0FAABkWDqHI/8g6XUlv6boW5LeVHI1fPSwkqKYPnb8KI0Y2Dd0FAAAkGHplLCB7v5rSa3u/oi7f1ISo2AZsqp5hx6aV3BfnQkAQMFJp4S1Rn+vMrN3mtkMSQMymKmg/blxuT5583PavqstdBQAAJBB6SxR8d9mVqXk9zz+VFKlpM9nNFUBm1BXLndpwdqtmjasOnQcAACQIemUsPvdfaekZkmnZjhPwZsYfSrytVWbKWEAAOSxdA5HzjGzJ8zsO9HhyKqMpypgIwf0VXlpkeas2Bw6CgAAyKADljB3H6fkF3a/Iumdkmab2UuZDlaoYjHTpKGVemVFc+goAAAgg9JZJ2yYpLdLOlHSdElzJT2e4VwF7apzJquiLJ0jxQAAIFel806/VMl1wb7t7v8nw3kgadJQVssHACDfpTMnbIak30r6sJk9ZWa/NbOLM5yroLW0tevmJxbruTc3hI4CAAAyJJ05YbMl3SLpJkkPSjpZ0pUZzlXQimMxfe++ebr75VWhowAAgAxJZ05Yo6RSSU9KekzSSe6+JNPBChmT8wEAyH/pzAk7y92bMp4EnUypr9Jtzy5Te8IVj1noOAAAoIelMycsZma/NrP/lSQzm8ScsMybWl+lHa3tWtS0NXQUAACQAemUsJsl3SdpaHT6DUmXZyoQkqbUV8lMWti0LXQUAACQAemUsBp3v11SQpLcvU1Se0ZTQeNqy/XKVWdq5pTBoaMAAIAMSKeEbTOzgZJckszsOCW/RxIZFIuZyktZsBUAgHyVTgn7gqRZksaa2RNKrhn22YymgiTpgdfW6FO3NKo94aGjAACAHtbtUIuZxZVcF+xkSRMlmaR57t7aC9kK3oZtu3T/a2u0eN02jRtUHjoOAADoQd2OhLl7u6QL3L3N3ee6+xwKWO+ZOqxKkjSH9cIAAMg76RyOfMLMfmZmJ5rZ0R1/Mp4MGldbrtKiGIu2AgCQh9KZ+X1U9PfVKee5pNN6Pg5SFcVjOnJIJSNhAADkoQOWMHc/tTeCYN+OGzNQC9ayYCsAAPmGNRCy3FfOOiJ0BAAAkAHpzAkDAABAD6OEZTl317uve0LX3vt66CgAAKAHpXU40szeJmlU6v7u/tsMZUIKM5O768Wlm0JHAQAAPeiAJczMfidprKSXtOc7I13JlfPRC6bUV2nW7JVyd5lZ6DgAAKAHpDMS1iBpkrvz3TmBTK2v0h+eWaol67drVE2/0HEAAEAPSGdO2BxJgzMdBPs3pT65cj6LtgIAkD/SGQmrkfSqmT0rqaXjTHc/N2Op0MmEugqdd9RQ1VaUho4CAAB6SDol7KpMh0D3Sopi+vH5M0LHAAAAPSidFfMf6Y0g6J67q3lHq6r7loSOAgAAesAB54SZ2XFm9pyZbTWzXWbWbmabeyMc9vjhv97QMdfcr/YEn48AACAfpDMx/2eSLpA0X1IfSZ+SdF0mQ2FvQ6v7qLXdtXLTjtBRAABAD0hrxXx3XyAp7u7t7n6TpJmZjYWuRgzsK0laumF74CQAAKAnpFPCtptZiaSXzOxaM/t8mpdDDxo5MLk+2JL1lDAAAPJBOmXqo9F+l0raJmm4pPdlMhT2NriyTCXxmJZs2BY6CgAA6AHpfDpyiZn1kTTE3b/VC5mwD/GY6YqZEzVpSGXoKAAAoAek8+nIc5T83sh7o9NHmdmsTAfD3j514hi9bVxN6BgAAKAHpHM48ipJx0raJEnu/pKk0RnMhP3Y1tKmOSuaxdd4AgCQ+9IpYa3u3vVLC9NqAWY208zmmdkCM/vKfvb5oJm9amZzzeyP6VxvobrtuWV6108f18btraGjAACAw5TO1xbNNbMPS4qb2XhJl0l68kAXMrO4kuuJnSFpuaTnzGyWu7+ass94Sf9X0tvdfaOZDTqUO1EoRg5ILlOxZP02DejHyvkAAOSydEbCPitpspJf3n2rpM2SLk/jcsdKWuDui9x9l6TbJJ3XZZ9PS7rO3TdKkruvTTd4IRrJWmEAAOSNdD4duV3S16I/B6Ne0rKU08slvbXLPhMkycyekBSXdJW733uQt1Mwhu8eCaOEAQCQ6/Zbwg70CUh3P7eHbn+8pFMkDZP0qJlNdfdNXbJcIukSSRoxYkQP3GxuKiuOa3BlGSUMAIA80N1I2PFKjmTdKukZSXaQ171CyYVdOwyLzku1XNIz7t4qabGZvaFkKXsudSd3v0HSDZLU0NBQ0B8NvPq8yaqrLAsdAwAAHKbu5oQNlvRVSVMk/VjJCfbr3P0Rd38kjanzdhkAAB80SURBVOt+TtJ4Mxsdfe3R+ZK6jq79XclRMJlZjZKHJxcd1D0oMO+YPFjTh1eHjgEAAA7TfktY9GXd97r7xyUdJ2mBpIfN7NJ0rtjd25T8qqP7JL0m6XZ3n2tmV5tZx6HM+yStN7NXJT0k6T/dff1h3J+817SlRffNXa2dre2howAAgMNg3S38aWalkt4p6QJJo5QcyfqNu3c9rNhrGhoavLGxMdTNBzdr9kpdduuLuu/ykzRxcEXoOAAAoBtm9ry7N+xrW3cT83+r5KHIeyR9y93nZCgfDkLqWmGUMAAAcld3E/M/ImmbpM9Jusxs97x8k+TuzjdJB8BaYQAA5If9ljB3T2chV/Sy6r4lqiwrYpkKAAByHEUrB40Y2JeRMAAAclw63x2JLPOd905TRRlPHQAAuYx38hw0pb4qdAQAAHCYOByZg1Zu2qFbnnxT67e2hI4CAAAOESUsB725fpu+OWuuXl+9JXQUAABwiChhOWjkwH6SxCckAQDIYZSwHDS4skzFcdOSDdtCRwEAAIeIEpaD4jHT8P59tZSRMAAAchYlLEeNGNiXw5EAAOQwlqjIUde+b5r6lfL0AQCQq3gXz1GDKstCRwAAAIeBw5E5avnG7fqfe17TwqatoaMAAIBDQAnLUdt3teuXjy7SnBXNoaMAAIBDQAnLUSMG9JXEWmEAAOQqSliOKiuOq66ylBIGAECOooTlsJED+mkpC7YCAJCTKGE5bMTAvtq4vTV0DAAAcAhYoiKHffs9U1VSRI8GACAX8Q6ewyhgAADkLt7Fc1gi4frC7S/p908vCR0FAAAcJEpYDovFTHNWNOv+19aEjgIAAA4SJSzHHT2iv15cukmJhIeOAgAADgIlLMcdPaK/mne0atE6lqoAACCXUMJy3NEjqyVJLyzdGDgJAAA4GJSwHDemplxvGdlfcbPQUQAAwEFgnbAcF4uZ/vKZt4WOAQAADhIjYXkikXC1MzkfAICcQQnLA3NWNOuoq/+pJxeuCx0FAACkiRKWB0YO7KstLW16Ycmm0FEAAECaKGF5oKKsWBPrKviEJAAAOYQSlidmjOivF5duZNFWAAByBCUsTxw9olqbd7Zp0bqtoaMAAIA0UMLyxHFjBurfTxmrPiWsOgIAQC7gHTtPDB/QV1fMPCJ0DAAAkCZGwvLIjl3tmr2MT0gCAJALKGF55FePLdJ51z2h5h2toaMAAIADoITlkaNH9JckvcRoGAAAWY8SlkemD6+SmfTCEtYLAwAg21HC8giLtgIAkDsoYXlmxoj+emnZJhZtBQAgy7FERZ75xNtH6f1vqQ8dAwAAHAAlLM9MqKsIHQEAAKSBw5F56KHX1+qeV1aFjgEAALrBSFgeuunJN7V2806dPXVI6CgAAGA/GAnLQ0cNr9Yba7ZoW0tb6CgAAGA/KGF5aMaIaiVcenl5c+goAABgPzJawsxsppnNM7MFZvaVbvZ7n5m5mTVkMk+hOGpYtSRWzgcAIJtlrISZWVzSdZLOkjRJ0gVmNmkf+1VI+pykZzKVpdD071eiUQP7at7qzaGjAACA/cjkxPxjJS1w90WSZGa3STpP0qtd9vsvSd+V9J8ZzFJw7vjM2zSwX0noGAAAYD8yeTiyXtKylNPLo/N2M7OjJQ1397u7uyIzu8TMGs2ssampqeeT5qGa8lKZWegYAABgP4JNzDezmKQfSPrigfZ19xvcvcHdG2prazMfLg9s2LZLX/rzbD02n9IKAEA2ymQJWyFpeMrpYdF5HSokTZH0sJm9Kek4SbOYnN8z+pXGNeullXps/rrQUQAAwD5ksoQ9J2m8mY02sxJJ50ua1bHR3ZvdvcbdR7n7KElPSzrX3RszmKlglBbFNWlopV5ayickAQDIRhkrYe7eJulSSfdJek3S7e4+18yuNrNzM3W72OOo4dV6ecUmtbUnQkcBAABdZPRri9z9Hkn3dDnvyv3se0omsxSiGSOqdfOTb+r11Vs0pb4qdBwAAJCCFfPz2Izh/TWmpp8272gNHQUAAHTBF3jnsRED++rBL50SOgYAANgHRsIKgLuHjgAAALqghOW5WbNX6phrHtDmnRySBAAgm1DC8lz/vsVat7VFLy9rDh0FAACkoITluWnDqiVJLy3bGDgJAABIRQnLc1V9ijW2tp9eWsairQAAZBNKWAE4anh/vbh0ExP0AQDIIixRUQBmThmsAf2K1dKWUFlxPHQcAAAgSlhBOGNSnc6YVBc6BgAASMHhyALR0taulZt2hI4BAAAilLACcfHNjfrETc+FjgEAACKUsAJx+pGDNG/NFi1YuzV0FAAAIEpYwThr6hCZSfe8sip0FAAAIEpYwairLFPDyP66+2VKGAAA2YASVkDeOXVIdEhyS+goAAAUPJaoKCDnTB+qqcOqNKamPHQUAAAKHiWsgAwsL9XA8tLQMQAAgDgcWXBWNe/QlXfO0cImPiUJAEBIlLACEzPT755eortmM0EfAICQKGEFpq6yTMeMHMBSFQAABEYJK0DvnManJAEACI0SVoDOmjJYZtLdL68OHQUAgIJFCStAgyrL9I5JdTILnQQAgMLFEhUF6pcfbQgdAQCAgsZIWAFzd63b2hI6BgAABYkSVsA+d9tL+vCvng4dAwCAgkQJK2ANo/rrjTVbNXdlc+goAAAUHEpYATt3+lCVFMV0+3PLQkcBAKDgUMIKWHXfEs2cPFh/f2mldra2h44DAEBBoYQVuA8dM1zNO1r1z1fXhI4CAEBBYYmKAnf8mIH65UffolMm1oaOAgBAQaGEFbhYzHTm5MGhYwAAUHA4HAm5u657aIF++9SboaMAAFAwKGGQmemZxRt0/cML1Z7w0HEAACgIlDBIks4/ZrhWNe/UY/ObQkcBAKAgUMIgSTr9yDoN6Fei2xtZMwwAgN5ACYMkqaQopvfMqNe/Xl2j9XyfJAAAGcenI7Hbh44ZriXrt2nzzjYNLC8NHQcAgLxGCcNuE+oqdOPHjwkdAwCAgsDhSOxl2YbtWrZhe+gYAADkNUoYOtnZ2q53/PBR/eqxRaGjAACQ1yhh6KSsOK7Tjhyku19epdb2ROg4AADkLUoY9nLe9KFav22XnliwLnQUAADyFiUMezl5Yq0qy4o066WVoaMAAJC3KGHYS2lRXGdPHaIHXl/LIUkAADKEJSqwT587fbz+88yJKo7T0wEAyARKGPZpSFWf0BEAAMhrGR3mMLOZZjbPzBaY2Vf2sf0LZvaqmb1sZg+Y2chM5sHBeX7JRl1449PatH1X6CgAAOSdjJUwM4tLuk7SWZImSbrAzCZ12e1FSQ3uPk3SHZKuzVQeHLySeExPLFive+esDh0FAIC8k8mRsGMlLXD3Re6+S9Jtks5L3cHdH3L3jqXZn5Y0LIN5cJCm1FdqdE0/3cmnJAEA6HGZLGH1kpalnF4enbc/F0v63wzmwUEyM507faieXrxeq5t3ho4DAEBeyYqPvpnZRyQ1SPrefrZfYmaNZtbY1NTUu+EK3LlHDZW7dNfLjIYBANCTMlnCVkgannJ6WHReJ2Z2uqSvSTrX3Vv2dUXufoO7N7h7Q21tbUbCYt/G1pbrA28ZpsFVZaGjAACQVzK5RMVzksab2Wgly9f5kj6cuoOZzZD0S0kz3X1tBrPgMHzvA9NDRwAAIO9kbCTM3dskXSrpPkmvSbrd3eea2dVmdm602/cklUv6s5m9ZGazMpUHh2fzzlbNXdkcOgYAAHkjo4u1uvs9ku7pct6VKT+fnsnbR8+57NYXNW/1Fj16xamsog8AQA/g3RRp+djxI7WqeScT9AEA6CGUMKTllAmDNH5QuW54dLHcPXQcAAByHiUMaYnFTJ8+cYxeW7VZjy9YFzoOAAA5jxKGtJ03Y6hqK0r1xIL1oaMAAJDzMjoxH/mltCiu+y4/SQP6lYSOAgBAzmMkDAelo4Bt2dkaOAkAALmNEoaDdudLK3TsNQ9oVfOO0FEAAMhZlDActKNH9Neu9oRueuLN0FEAAMhZlDActOED+ursqUP0x2eWajOHJQEAOCSUMBySS04co60tbbrt2aWhowAAkJMoYTgkU4dV6fgxA/W7p5cokWDxVgAADhZLVOCQXXnOJJWXFikWs9BRAADIOZQwHLIjh1Tu/tndZUYZAwAgXRyOxGHZsrNVF930rG59dlnoKAAA5BRKGA5LeWmRmne06rqHFmhXWyJ0HAAAcgYlDIfFzHT56RO0YtMO/fl5RsMAAEgXJQyH7aTxNZoxolrXPchoGAAA6aKE4bCZmT5/+gStbN6pO55fHjoOAAA5gRKGHnHi+Bp9+z1T9c5pQ0JHAQAgJ7BEBXqEmenDbx0ROgYAADmDkTD0qKcWrtcnbnpWLW3toaMAAJDVKGHoUW2JhB6a16TbG5kbBgBAdyhh6FEnjKvRMaP662cPztfOVkbDAADYH0oYepSZ6QtnTNSazS36wzNLQ8cBACBrUcLQ444fO1BvGztQ1z+8QNt3tYWOAwBAVuLTkciIL888QvNWb1FJnJ4PAMC+UMKQEdOHV2v68OrQMQAAyFqUMGSMu+vmJ9+Uu/TJE0aHjgMAQFbhWBEyxsz09KL1+uG/3tCm7btCxwEAIKtQwpBRnz9jgrbuatMNjy4KHQUAgKxCCUNGHTG4UudMG6qbnnhT67a2hI4DAEDWoIQh4z53+ni1tLXr5w8tDB0FAICswcR8ZNzY2nJ94YwJOnb0wNBRAADIGpQw9IpLTxsfOgIAAFmFw5HoNW3tCX3rH3P168cXh44CAEBwlDD0mnjMtGzDdn3/vnlatmF76DgAAARFCUOvMTNdfd4UxUz66t9ekbuHjgQAQDCUMPSqodV9dMXMI/TY/HX624srQscBACAYShh63UeOG6mjR1Tre/fNU2t7InQcAACC4NOR6HXxmOn7H5guM1NxnP8HAAAKE++ACGJMbblG1/STu+ux+U2h4wAA0OsoYQjqrpdX6aO/flY/uv+N0FEAAOhVHI5EUGdPHaJH3mjSj+6fr4RLnz99vMwsdCwAADKOEoag4jHTte+bpphJP3lgvtxdXzhjAkUMAJD3KGEILhYzfee90xQz0/UPL9Q504dqQl1F6FgAAGQUJQxZIRYzffs9U3XhW0dqQl2F3F0Lm7Zp3KDy0NEAAMgIJuYja8RipqnDqiRJD76+Vqf/4BFd+scXtLBpa+BkAAD0PEoYslLDqAH67Gnj9ODra3XGDx7RFXfM1pL120LHAgCgx2S0hJnZTDObZ2YLzOwr+9heamZ/irY/Y2ajMpkHuaOqT7G++I6JevSKU3XR20br7y+u1Md+8+zu75vc1tIWOCEAAIcnY3PCzCwu6TpJZ0haLuk5M5vl7q+m7HaxpI3uPs7Mzpf0XUkfylQm5J6a8lJdec4kXXLSGC1Zv01mptb2hE689iGNqy3XzCmDNXlopSbUVah/v5LQcQEASFsmJ+YfK2mBuy+SJDO7TdJ5klJL2HmSrop+vkPSz8zMvGO4A4gMrirT4KoySdKutoQuetso3fXySl19156X09fOPlKfPmmMVm7aod8/vUSSlPpCete0IZo8tEqrmnfovjmrVVocV3E8po7FMN4+rkaDq8q0ctMOPblwvdoTCbUnpHZ3JRKuMycP1uCqMi3bsF0vLN2oolhMRXHbffnjxg5UZVmxlm3YrjfXb1Of4rjKiuPqUxJXn+K46irLFI+ZVm7aoUVN27RtV5t2trarOB5TaVFMJ4yvUWlRXKubd2rtlp3q+C3ouA/T6qsUi5lWN+9U845WxWNSzExFsZjicVN9dR9JyVHC1vaETCaZZJbcr7w0+evetKVFm3e2aldbQq3tCcXMVFYc3/0hiKYtLWppa+/0+JfEYxpUmXz8129tUXvCZWa7r7s4bqooK5Ykbd/VptZ2V1t7Qu0JV2vCVRw3DapIXn7t5p1yJZcniZupuCimknhMJUX7HphPJHz3/pKSt63k/eq6lIm7y33f2wAg22SyhNVLWpZyermkt+5vH3dvM7NmSQMlrctgLuS4fqVFuuzfxuuyfxuvlZt2aN6aLZq/ZouOHztQUrJE/OqxRbv376hJ0+qrNHlolRas3aqr/vHqXtd70yeO0eCqMr2yollf+vPsvbZPHlqpwVVlenbxBn1xH9vvuexETRparIfmrdWVd87da/vjXz5Vw/r31d9eXKHv3Tdvr+0vXXmGSoviuuWpN3X9wwv32j7/mrMUk+m6hxbod1HJ7FASj+mNa86SJH3jzjn66wsrOm3v37dYL175DknSV//2iv716ppO24cP6KPHrjhNknT5n17UEwvWd9p+xOAK3Xv5SZKkT97SqNnLNnXa3jCyv+74zNskSef+7AktWNv5wxQnT6jVLZ88VpL07uue0MrmnZ22nz11sH5+4VskScdec7827WhVIuFqj0rVBxuG6dr3T5ckjf/aPUp0+W/aJ94+St88Z7Ja2hI64hv37j4/HjPFTPr3U8bp82dM0LqtLTrhuw+qqy+eMVGfPmmMlm3YrjN/9KhMyQ+KJC9v+spZR+iDDcM1b/UWfeTXz0QFORnCzPStcyfr7KlDNHvZJl166wtyT5bFtoSrPeH6fx+crlMnDtLj89fp0ltfUFF0vR3F8icXzNAxowboX6+u0Tf+Pmd3Lkv2aN3wsQZNqa/SXS+v1LX3zlMsKr9myRQ3XXSMRg7sp9ufW6YfPzB/r/v3139/m+oqy3TTE4t142OLO20zk+753ImqLCvWDY8u1O2Ny/eUXCVv4+7LTlQ8ZvrZg/N19yurlfr/5NKimO689ARJ0vfue10Pvt75a8iq+xTr1kuOkyRd/Y9X9fSizq+todVluvHjx0iSvv73V/TK8mYloscv4a4xtf12vzYu/eMLemPNFsVjMcVjUtxMk4ZW6X/eO3X39uUbd3S6/reM7K9vvGuSJOnim5/Tuq0tSriUiF5bJ06o0f8960hJ0od++ZS272rfXeJN0hmT6vQfp46TJH3wF08pkXLfXdI7pw7RJ08YrZ2t7frQDU9LqWMIZvpgwzBd+NaR2rR9ly6+pTF5dsrje+FxI3TeUfVa1bxDl/7xxT0XVfI5vvjE0Tpz8mAtXrdNX/3rK/LodddxM5eeNk4njq/Va6s266pZc3fn6vjf23/OnKhjRg3Q80s26n/uea3T82omff2dkzSlvkpPLlynn3R57ZhM//XuKRo3qFwPvb5Wv3psUcp/DpM/fP8D0zWsf1/d88qq3f/5je66JOkn58/QwPJS/fWF5brj+eWdskvSjR9vUL/SIt367FLd9fLK3dk63PKJYxWLmX7z+GI9+PraTtdfEo/p1xclXzvXP7xQTy5cl7LdVFlWpJ99+GhJ0g//9YZeWLqx0/2rr+6j77xvmkLKiSUqzOwSSZdI0ogRIwKnQTYZWt1HQ6v76NSJg3afN314teZfc/Z+L3PcmIF64RtnaFdbQrvaErvPr60olSSdMK5Gj11xavJN2Eyx6B/7yj7JkZ53TK7TAyNOVlu7q7V9z+VH1/STJJ01ZYgmDanUjtZ27djVrh2t7drZ2q6K0uTlzztqqI4ZNUD9SuMqLYqrLZFQS2ti90jSe2fUq2Fkf0l7/iEzJbNI0vnHDtfxYweqPXqDb094pxG/dx9VrylDq+TS7jfL0pRRpk++fbTeNW2ISotiKorFlHDvNAr16RPH6Lyj6js9ZlXRfZekz5w8Vuu3Jd/IOkaeOh47SbrkpDHavKNVxfHkSGFRzDQ0GqWTpC+fdYS2trQpkXC1tifzjxzYd/f2848Zrpb2hOJRSYnHTJOHVu3efvnpE3a/gXo07DVjRLWkZOn6/OkT5EqOXna82b4lejz7FMf18eNHqavJ9ZWSkgX/wreOSJYo33MdIwck81WUFen0I+s6PTfuvnuUtrysSA0jB8hMKoqZ4rGYimKmumgUsLaiVOdOH6q2RPK6kyOKyaIiSYMqSnXyhNrk9cp3v1lVRq+Ngf1K9ZaR/ZXw6L5Fl+94/uqqynTcmIGd3sSk5JuVJA3r33f3f1aS2ZO3UxyL7c43oa48emz3ZOi4uuq+JRrWP/lcdpxXnPLa6Z+yvUNF2Z63mYHlJZ1eC5J3eu1UlBWrum+JYqbdBXho1Z79hw/oq7b2ZLlNePLvfiXx3dvLS4t2/5526FMcT7n+IrW7Jwusks9h/757pjHUlJdqR2v77tdXwr3T705JUUydf9uk4njykUh9Hs06Hj+prCgePV6mPsXx3Y9px+PbMWJrMpUVx2SyTvukPpXtHf/7sE5/7cUkWWzPf0A7MpUUxTo9r4lESiFydf7PTdTkOv4NSfief+9sHwHaE3u2p5Ys38f2TtcRaW1PaGdrIvlvyj7uW2t7Qjta26PrT15ra8pzs7O1XVujucLe+WHaa3uHbbs6j/iHYJk68mdmx0u6yt3PjE7/X0ly9/9J2ee+aJ+nzKxI0mpJtd0djmxoaPDGxsaMZAYAAOhJZva8uzfsa1smPx35nKTxZjbazEoknS9pVpd9Zkn6ePTz+yU9yHwwAABQCDJ2ODKa43WppPskxSX9xt3nmtnVkhrdfZakX0v6nZktkLRByaIGAACQ9zI6J8zd75F0T5fzrkz5eaekD2QyAwAAQDZixXwAAIAAKGEAAAABUMIAAAACoIQBAAAEQAkDAAAIgBIGAAAQACUMAAAgAEoYAABAAJQwAACAAChhAAAAAVDCAAAAAqCEAQAABEAJAwAACIASBgAAEAAlDAAAIABz99AZDoqZNUla0gs3VSNpXS/cDg4Pz1Pu4LnKHTxXuYPnKvuNdPfafW3IuRLWW8ys0d0bQudA93iecgfPVe7gucodPFe5jcORAAAAAVDCAAAAAqCE7d8NoQMgLTxPuYPnKnfwXOUOnqscxpwwAACAABgJAwAACIAS1oWZzTSzeWa2wMy+EjoP9jCz4Wb2kJm9amZzzexz0fkDzOxfZjY/+rt/6KyQzCxuZi+a2V3R6dFm9kz0u/UnMysJnRGSmVWb2R1m9rqZvWZmx/M7lZ3M7PPRv31zzOxWMyvj9yq3UcJSmFlc0nWSzpI0SdIFZjYpbCqkaJP0RXefJOk4Sf8RPT9fkfSAu4+X9EB0GuF9TtJrKae/K+mH7j5O0kZJFwdJha5+LOledz9C0nQlnzN+p7KMmdVLukxSg7tPkRSXdL74vcpplLDOjpW0wN0XufsuSbdJOi9wJkTcfZW7vxD9vEXJN4t6JZ+jW6LdbpH07jAJ0cHMhkl6p6Qbo9Mm6TRJd0S78DxlATOrknSSpF9LkrvvcvdN4ncqWxVJ6mNmRZL6Slolfq9yGiWss3pJy1JOL4/OQ5Yxs1GSZkh6RlKdu6+KNq2WVBcoFvb4kaQrJCWi0wMlbXL3tug0v1vZYbSkJkk3RYeObzSzfuJ3Kuu4+wpJ35e0VMny1SzpefF7ldMoYcg5ZlYu6S+SLnf3zanbPPlxXz7yG5CZvUvSWnd/PnQWHFCRpKMlXe/uMyRtU5dDj/xOZYdoXt55ShbnoZL6SZoZNBQOGyWssxWShqecHhadhyxhZsVKFrA/uPtfo7PXmNmQaPsQSWtD5YMk6e2SzjWzN5U8pH+akvOOqqPDKBK/W9liuaTl7v5MdPoOJUsZv1PZ5/+3dz+hWhVxGMe/T4aRGIVQm6LEiqigbgQR/QHBVtGixa0glYvQrk2LIAwjCtrWKshFgZGL/qAkrSKLSy5CI63IWhmVUBQUkUEh9msxc9HrprzQnfu+fT+r950z72EOhzk875w5Z+4Bvq6qn6rqJLCH1tfsVxPMELbYIeDa/rTJatqkx32D26Suzyt6Gfiyqp4/Y9M+YK5/ngPeXu626bSq2l5VV1TVelofer+qNgMfALO9mudpBaiqH4DvklzXizYBR7FPrUTfArcnWdOvhQvnyn41wXxZ61mS3Eubz7IKeKWqnhvcJHVJ7gI+BD7n9FyjJ2nzwt4ArgS+AR6sqp+HNFKLJNkIPF5V9yXZQBsZWwccBrZU1Z8j2ydIMkN7gGI1cAzYRvuDbp9aYZI8AzxEe1L8MPAIbQ6Y/WpCGcIkSZIG8HakJEnSAIYwSZKkAQxhkiRJAxjCJEmSBjCESZIkDWAIk6R/KcnGJO+Mboek6WAIkyRJGsAQJmnqJNmS5GCSI0l2JlmV5ESSF5J8kWR/kkt73ZkkHyX5LMnevkYfSa5J8l6ST5N8kuTqvvu1Sd5K8lWS3f3t5ZJ0zgxhkqZKkutpbxW/s6pmgFPAZtqCxx9X1Y3APPB0/8mrwBNVdRNtNYaF8t3Ai1V1M3AH8H0vvwV4DLgB2EBbv0+Sztn5/1xFkibKJuBW4FAfpLqQtgD1X8Drvc5rwJ4kFwOXVNV8L98FvJnkIuDyqtoLUFV/APT9Hayq4/37EWA9cOC/PyxJ08YQJmnaBNhVVdsXFSZPnVVvqWu2nbku3ym8jkpaIm9HSpo2+4HZJJcBJFmX5Cra9W6213kYOFBVvwK/JLm7l28F5qvqN+B4kvv7Pi5IsmZZj0LS1PMfnKSpUlVHk+wA3k1yHnASeBT4Hbitb/uRNm8MYA54qYesY8C2Xr4V2Jnk2b6PB5bxMCT9D6RqqSPykjQ5kpyoqrWj2yFJC7wdKUmSNIAjYZIkSQM4EiZJkjSAIUySJGkAQ5gkSdIAhjBJkqQBDGGSJEkDGMIkSZIG+BuZXCYy3FT2uQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsIq2Y3V5njb",
        "colab_type": "text"
      },
      "source": [
        "## Fit one by one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW1QxXVg6gYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u_agent_one_by_one = CCEMAgent((2,), (1,), percentile_param=30, action_max=env.u_action_max, reward_param=-1)\n",
        "v_agent_one_by_one = CCEMAgent((2,), (1,), percentile_param=70, action_max=env.v_action_max, reward_param=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo2hX83F6UxM",
        "colab_type": "code",
        "outputId": "0a0ed64c-99ec-478c-b8ee-a93211851c5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "u_fit_agent_one_by_one, mean_rewards_one_by_one =\\\n",
        "fit_agents_one_by_one(u_agent_one_by_one, v_agent_one_by_one, env, \\\n",
        "                       n_epochs=301, n_sessions=100, n_iter_for_fit=20, epsilon=-1, n_iter_debug=50)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, current agent: u_, mean reward: 0.6217259537261607\n",
            "epoch: 1, current agent: u_, mean reward: 0.4602930440226248\n",
            "epoch: 2, current agent: u_, mean reward: 0.29830563390050197\n",
            "epoch: 3, current agent: u_, mean reward: 0.1778145196453188\n",
            "epoch: 4, current agent: u_, mean reward: 0.09616327476300851\n",
            "epoch: 5, current agent: u_, mean reward: 0.033047069052012934\n",
            "epoch: 6, current agent: u_, mean reward: 0.016104570400324945\n",
            "epoch: 7, current agent: u_, mean reward: 0.010773317676115288\n",
            "epoch: 8, current agent: u_, mean reward: 0.011016364589016251\n",
            "epoch: 9, current agent: u_, mean reward: 0.010102929985774249\n",
            "epoch: 10, current agent: u_, mean reward: 0.007221379664705387\n",
            "epoch: 11, current agent: u_, mean reward: 0.006578172394736825\n",
            "epoch: 12, current agent: u_, mean reward: 0.007500003274676279\n",
            "epoch: 13, current agent: u_, mean reward: 0.007039169666631206\n",
            "epoch: 14, current agent: u_, mean reward: 0.006497921376231089\n",
            "epoch: 15, current agent: u_, mean reward: 0.0053482894561115\n",
            "epoch: 16, current agent: u_, mean reward: 0.0073536745542278304\n",
            "epoch: 17, current agent: u_, mean reward: 0.0056923116683671015\n",
            "epoch: 18, current agent: u_, mean reward: 0.0042504938951203365\n",
            "epoch: 19, current agent: u_, mean reward: 0.004024142329412235\n",
            "\n",
            "\n",
            "epoch: 20, current agent: v_, mean reward: 0.002810245642133895\n",
            "epoch: 21, current agent: v_, mean reward: 0.0019414995957293289\n",
            "epoch: 22, current agent: v_, mean reward: 0.0023610578422828517\n",
            "epoch: 23, current agent: v_, mean reward: 0.0027857287993965345\n",
            "epoch: 24, current agent: v_, mean reward: 0.01320646647185864\n",
            "epoch: 25, current agent: v_, mean reward: 0.033551279371310506\n",
            "epoch: 26, current agent: v_, mean reward: 0.06236035775010574\n",
            "epoch: 27, current agent: v_, mean reward: 0.0993009076005836\n",
            "epoch: 28, current agent: v_, mean reward: 0.13266719570233712\n",
            "epoch: 29, current agent: v_, mean reward: 0.17112051065137354\n",
            "epoch: 30, current agent: v_, mean reward: 0.21701077051894577\n",
            "epoch: 31, current agent: v_, mean reward: 0.26169534996164096\n",
            "epoch: 32, current agent: v_, mean reward: 0.31812245298233743\n",
            "epoch: 33, current agent: v_, mean reward: 0.36892988807624055\n",
            "epoch: 34, current agent: v_, mean reward: 0.41432374417452167\n",
            "epoch: 35, current agent: v_, mean reward: 0.4536438529926704\n",
            "epoch: 36, current agent: v_, mean reward: 0.4872871727233515\n",
            "epoch: 37, current agent: v_, mean reward: 0.5299426792763151\n",
            "epoch: 38, current agent: v_, mean reward: 0.5719800975995399\n",
            "epoch: 39, current agent: v_, mean reward: 0.6153122932929213\n",
            "\n",
            "\n",
            "epoch: 40, current agent: u_, mean reward: 0.6851364741576873\n",
            "epoch: 41, current agent: u_, mean reward: 0.5041687366652066\n",
            "epoch: 42, current agent: u_, mean reward: 0.3725403721275884\n",
            "epoch: 43, current agent: u_, mean reward: 0.2390564340579521\n",
            "epoch: 44, current agent: u_, mean reward: 0.15432119133979288\n",
            "epoch: 45, current agent: u_, mean reward: 0.08533645169345588\n",
            "epoch: 46, current agent: u_, mean reward: 0.04064176671668245\n",
            "epoch: 47, current agent: u_, mean reward: 0.011676022056392964\n",
            "epoch: 48, current agent: u_, mean reward: 0.0047887158526558485\n",
            "epoch: 49, current agent: u_, mean reward: 0.004087266465544463\n",
            "\n",
            "--------------------TEST BEGIN--------------------\n",
            "\n",
            "epoch: 0, mean reward: 0.5099999660259379\n",
            "epoch: 1, mean reward: 0.6043418605656291\n",
            "epoch: 2, mean reward: 0.7117908003653604\n",
            "epoch: 3, mean reward: 0.8282608497041308\n",
            "epoch: 4, mean reward: 0.9384770809701435\n",
            "epoch: 5, mean reward: 1.0650302320849512\n",
            "epoch: 6, mean reward: 1.1908679224706027\n",
            "epoch: 7, mean reward: 1.3328403787291958\n",
            "epoch: 8, mean reward: 1.4469287669432902\n",
            "epoch: 9, mean reward: 1.5564748620605604\n",
            "epoch: 10, mean reward: 1.6628128471402417\n",
            "epoch: 11, mean reward: 1.76772471774419\n",
            "epoch: 12, mean reward: 1.8930904247627551\n",
            "epoch: 13, mean reward: 1.995457821142398\n",
            "epoch: 14, mean reward: 2.083833076834731\n",
            "epoch: 15, mean reward: 2.185508187853968\n",
            "epoch: 16, mean reward: 2.2925656109661845\n",
            "epoch: 17, mean reward: 2.415076305034053\n",
            "epoch: 18, mean reward: 2.5208820548271937\n",
            "epoch: 19, mean reward: 2.6219624634287766\n",
            "\n",
            "---------------------TEST END---------------------\n",
            "\n",
            "epoch: 50, current agent: u_, mean reward: 0.003070719310976358\n",
            "epoch: 51, current agent: u_, mean reward: 0.0034696326909928717\n",
            "epoch: 52, current agent: u_, mean reward: 0.002707628613651924\n",
            "epoch: 53, current agent: u_, mean reward: 0.002815028997868533\n",
            "epoch: 54, current agent: u_, mean reward: 0.0018357221160523122\n",
            "epoch: 55, current agent: u_, mean reward: 0.0027479882106347824\n",
            "epoch: 56, current agent: u_, mean reward: 0.002224251171677115\n",
            "epoch: 57, current agent: u_, mean reward: 0.0019939084935493108\n",
            "epoch: 58, current agent: u_, mean reward: 0.0020730854364059766\n",
            "epoch: 59, current agent: u_, mean reward: 0.002255547600716458\n",
            "\n",
            "\n",
            "epoch: 60, current agent: v_, mean reward: 0.001074348099378127\n",
            "epoch: 61, current agent: v_, mean reward: 0.002363262104093285\n",
            "epoch: 62, current agent: v_, mean reward: 0.008247420081482269\n",
            "epoch: 63, current agent: v_, mean reward: 0.01704372491739314\n",
            "epoch: 64, current agent: v_, mean reward: 0.03153597408131701\n",
            "epoch: 65, current agent: v_, mean reward: 0.04968424976839665\n",
            "epoch: 66, current agent: v_, mean reward: 0.0764450512880071\n",
            "epoch: 67, current agent: v_, mean reward: 0.10493533481229683\n",
            "epoch: 68, current agent: v_, mean reward: 0.14049336181086136\n",
            "epoch: 69, current agent: v_, mean reward: 0.17751186802234886\n",
            "epoch: 70, current agent: v_, mean reward: 0.2187221566486918\n",
            "epoch: 71, current agent: v_, mean reward: 0.26856291206912597\n",
            "epoch: 72, current agent: v_, mean reward: 0.30816759509882813\n",
            "epoch: 73, current agent: v_, mean reward: 0.3585948026445408\n",
            "epoch: 74, current agent: v_, mean reward: 0.41320275225291225\n",
            "epoch: 75, current agent: v_, mean reward: 0.47419975706764284\n",
            "epoch: 76, current agent: v_, mean reward: 0.5422797112363341\n",
            "epoch: 77, current agent: v_, mean reward: 0.6081154865429445\n",
            "epoch: 78, current agent: v_, mean reward: 0.6751659761306076\n",
            "epoch: 79, current agent: v_, mean reward: 0.7434667502225747\n",
            "\n",
            "\n",
            "epoch: 80, current agent: u_, mean reward: 0.8227107754162956\n",
            "epoch: 81, current agent: u_, mean reward: 0.7149426987902392\n",
            "epoch: 82, current agent: u_, mean reward: 0.6033813203021894\n",
            "epoch: 83, current agent: u_, mean reward: 0.4966683769456493\n",
            "epoch: 84, current agent: u_, mean reward: 0.4090818007716321\n",
            "epoch: 85, current agent: u_, mean reward: 0.32661873103615713\n",
            "epoch: 86, current agent: u_, mean reward: 0.27036711809662417\n",
            "epoch: 87, current agent: u_, mean reward: 0.2126300597879003\n",
            "epoch: 88, current agent: u_, mean reward: 0.16578049637009076\n",
            "epoch: 89, current agent: u_, mean reward: 0.12582927225861104\n",
            "epoch: 90, current agent: u_, mean reward: 0.08727789239517648\n",
            "epoch: 91, current agent: u_, mean reward: 0.0608551340789871\n",
            "epoch: 92, current agent: u_, mean reward: 0.03787971540465204\n",
            "epoch: 93, current agent: u_, mean reward: 0.02419916912188315\n",
            "epoch: 94, current agent: u_, mean reward: 0.010639271472378952\n",
            "epoch: 95, current agent: u_, mean reward: 0.0033691158742809677\n",
            "epoch: 96, current agent: u_, mean reward: 0.0009416073580819372\n",
            "epoch: 97, current agent: u_, mean reward: 0.0008762787534655559\n",
            "epoch: 98, current agent: u_, mean reward: 0.0007034812106016526\n",
            "epoch: 99, current agent: u_, mean reward: 0.0009102918584949232\n",
            "\n",
            "\n",
            "\n",
            "--------------------TEST BEGIN--------------------\n",
            "\n",
            "epoch: 0, mean reward: 0.037880931609247284\n",
            "epoch: 1, mean reward: 0.05743705120325917\n",
            "epoch: 2, mean reward: 0.08159523250335188\n",
            "epoch: 3, mean reward: 0.1063436412363157\n",
            "epoch: 4, mean reward: 0.13241285800947847\n",
            "epoch: 5, mean reward: 0.15870568031069593\n",
            "epoch: 6, mean reward: 0.18569925618240102\n",
            "epoch: 7, mean reward: 0.21016589633870733\n",
            "epoch: 8, mean reward: 0.23490234033037755\n",
            "epoch: 9, mean reward: 0.25997214135222163\n",
            "epoch: 10, mean reward: 0.2913055488155655\n",
            "epoch: 11, mean reward: 0.32216906143647456\n",
            "epoch: 12, mean reward: 0.35644075346447524\n",
            "epoch: 13, mean reward: 0.3905459068473728\n",
            "epoch: 14, mean reward: 0.4184318259862954\n",
            "epoch: 15, mean reward: 0.4429115181163461\n",
            "epoch: 16, mean reward: 0.47021730689788177\n",
            "epoch: 17, mean reward: 0.4929304758224076\n",
            "epoch: 18, mean reward: 0.5274840487278826\n",
            "epoch: 19, mean reward: 0.5446634613024613\n",
            "\n",
            "---------------------TEST END---------------------\n",
            "\n",
            "epoch: 100, current agent: v_, mean reward: 0.0003543159124234829\n",
            "epoch: 101, current agent: v_, mean reward: 0.00047734081138285975\n",
            "epoch: 102, current agent: v_, mean reward: 0.0007552667702548199\n",
            "epoch: 103, current agent: v_, mean reward: 0.002915949316013677\n",
            "epoch: 104, current agent: v_, mean reward: 0.006785917280988014\n",
            "epoch: 105, current agent: v_, mean reward: 0.012914564652561038\n",
            "epoch: 106, current agent: v_, mean reward: 0.01994518518039266\n",
            "epoch: 107, current agent: v_, mean reward: 0.027333472246262414\n",
            "epoch: 108, current agent: v_, mean reward: 0.038224156846851993\n",
            "epoch: 109, current agent: v_, mean reward: 0.05142342736562321\n",
            "epoch: 110, current agent: v_, mean reward: 0.06678854234385347\n",
            "epoch: 111, current agent: v_, mean reward: 0.08334426519826961\n",
            "epoch: 112, current agent: v_, mean reward: 0.09793583436976132\n",
            "epoch: 113, current agent: v_, mean reward: 0.1158034529408542\n",
            "epoch: 114, current agent: v_, mean reward: 0.13016546509433147\n",
            "epoch: 115, current agent: v_, mean reward: 0.14721182217629797\n",
            "epoch: 116, current agent: v_, mean reward: 0.16959872272487014\n",
            "epoch: 117, current agent: v_, mean reward: 0.19561713293409103\n",
            "epoch: 118, current agent: v_, mean reward: 0.21794205824185245\n",
            "epoch: 119, current agent: v_, mean reward: 0.23703296045114858\n",
            "\n",
            "\n",
            "epoch: 120, current agent: u_, mean reward: 0.26413301559469615\n",
            "epoch: 121, current agent: u_, mean reward: 0.21648310458626083\n",
            "epoch: 122, current agent: u_, mean reward: 0.17990959037852255\n",
            "epoch: 123, current agent: u_, mean reward: 0.14676371075219152\n",
            "epoch: 124, current agent: u_, mean reward: 0.12058435504402064\n",
            "epoch: 125, current agent: u_, mean reward: 0.09262200018440156\n",
            "epoch: 126, current agent: u_, mean reward: 0.07172352639327202\n",
            "epoch: 127, current agent: u_, mean reward: 0.05305925875658225\n",
            "epoch: 128, current agent: u_, mean reward: 0.03724414059123982\n",
            "epoch: 129, current agent: u_, mean reward: 0.02629048744629517\n",
            "epoch: 130, current agent: u_, mean reward: 0.015380537971130048\n",
            "epoch: 131, current agent: u_, mean reward: 0.007561294591422641\n",
            "epoch: 132, current agent: u_, mean reward: 0.002243490827305146\n",
            "epoch: 133, current agent: u_, mean reward: 0.0004905878601371928\n",
            "epoch: 134, current agent: u_, mean reward: 0.0003218801173624375\n",
            "epoch: 135, current agent: u_, mean reward: 0.00036742578433073805\n",
            "epoch: 136, current agent: u_, mean reward: 0.0003420073115262456\n",
            "epoch: 137, current agent: u_, mean reward: 0.00030123280382062553\n",
            "epoch: 138, current agent: u_, mean reward: 0.0002713205484128082\n",
            "epoch: 139, current agent: u_, mean reward: 0.00029838230115878045\n",
            "\n",
            "\n",
            "epoch: 140, current agent: v_, mean reward: 0.00011836206497023726\n",
            "epoch: 141, current agent: v_, mean reward: 0.0001438768939190969\n",
            "epoch: 142, current agent: v_, mean reward: 0.0002076477093658495\n",
            "epoch: 143, current agent: v_, mean reward: 0.0003913585832898506\n",
            "epoch: 144, current agent: v_, mean reward: 0.0011939007894680095\n",
            "epoch: 145, current agent: v_, mean reward: 0.002785027116446415\n",
            "epoch: 146, current agent: v_, mean reward: 0.005206468923070076\n",
            "epoch: 147, current agent: v_, mean reward: 0.00789649414446426\n",
            "epoch: 148, current agent: v_, mean reward: 0.011465706265710895\n",
            "epoch: 149, current agent: v_, mean reward: 0.014639469117114485\n",
            "\n",
            "--------------------TEST BEGIN--------------------\n",
            "\n",
            "epoch: 0, mean reward: 0.4411539006613435\n",
            "epoch: 1, mean reward: 0.5011955638429355\n",
            "epoch: 2, mean reward: 0.5614969347528884\n",
            "epoch: 3, mean reward: 0.622046831854988\n",
            "epoch: 4, mean reward: 0.6841621304300761\n",
            "epoch: 5, mean reward: 0.7397959727408561\n",
            "epoch: 6, mean reward: 0.8016576806767768\n",
            "epoch: 7, mean reward: 0.8589223143680145\n",
            "epoch: 8, mean reward: 0.9169417457764851\n",
            "epoch: 9, mean reward: 0.9636828080107114\n",
            "epoch: 10, mean reward: 1.0034450200854839\n",
            "epoch: 11, mean reward: 1.0572408842368386\n",
            "epoch: 12, mean reward: 1.1079899542926481\n",
            "epoch: 13, mean reward: 1.1471070031123287\n",
            "epoch: 14, mean reward: 1.1787953505048074\n",
            "epoch: 15, mean reward: 1.2013910592204682\n",
            "epoch: 16, mean reward: 1.2259605558332212\n",
            "epoch: 17, mean reward: 1.2663813799305836\n",
            "epoch: 18, mean reward: 1.3061127620199757\n",
            "epoch: 19, mean reward: 1.3459693208840005\n",
            "\n",
            "---------------------TEST END---------------------\n",
            "\n",
            "epoch: 150, current agent: v_, mean reward: 0.018380273795084803\n",
            "epoch: 151, current agent: v_, mean reward: 0.023169355043013838\n",
            "epoch: 152, current agent: v_, mean reward: 0.027449399429183605\n",
            "epoch: 153, current agent: v_, mean reward: 0.031772432687538626\n",
            "epoch: 154, current agent: v_, mean reward: 0.03656943274031357\n",
            "epoch: 155, current agent: v_, mean reward: 0.04271079767791613\n",
            "epoch: 156, current agent: v_, mean reward: 0.050397467148523445\n",
            "epoch: 157, current agent: v_, mean reward: 0.05683561092335864\n",
            "epoch: 158, current agent: v_, mean reward: 0.06339174941531645\n",
            "epoch: 159, current agent: v_, mean reward: 0.07031684712165875\n",
            "\n",
            "\n",
            "epoch: 160, current agent: u_, mean reward: 0.07839246636429498\n",
            "epoch: 161, current agent: u_, mean reward: 0.06477026729055703\n",
            "epoch: 162, current agent: u_, mean reward: 0.05148044162139962\n",
            "epoch: 163, current agent: u_, mean reward: 0.03829944513722977\n",
            "epoch: 164, current agent: u_, mean reward: 0.02840709216193611\n",
            "epoch: 165, current agent: u_, mean reward: 0.019969052617106752\n",
            "epoch: 166, current agent: u_, mean reward: 0.013511161040749342\n",
            "epoch: 167, current agent: u_, mean reward: 0.008759611431559981\n",
            "epoch: 168, current agent: u_, mean reward: 0.00479184554377345\n",
            "epoch: 169, current agent: u_, mean reward: 0.0025987436872360087\n",
            "epoch: 170, current agent: u_, mean reward: 0.0010934839481365828\n",
            "epoch: 171, current agent: u_, mean reward: 0.0002688140508298704\n",
            "epoch: 172, current agent: u_, mean reward: 0.00017894452692244253\n",
            "epoch: 173, current agent: u_, mean reward: 0.00015939688764913775\n",
            "epoch: 174, current agent: u_, mean reward: 0.00016848027314176692\n",
            "epoch: 175, current agent: u_, mean reward: 0.0001749071283400485\n",
            "epoch: 176, current agent: u_, mean reward: 0.00012701303513337563\n",
            "epoch: 177, current agent: u_, mean reward: 0.00015932990101673599\n",
            "epoch: 178, current agent: u_, mean reward: 0.00014100262045124934\n",
            "epoch: 179, current agent: u_, mean reward: 0.0001366926320962415\n",
            "\n",
            "\n",
            "epoch: 180, current agent: v_, mean reward: 5.775474493724769e-05\n",
            "epoch: 181, current agent: v_, mean reward: 6.578647477188809e-05\n",
            "epoch: 182, current agent: v_, mean reward: 0.00016264067858916904\n",
            "epoch: 183, current agent: v_, mean reward: 0.000535849436518026\n",
            "epoch: 184, current agent: v_, mean reward: 0.0013251966289901545\n",
            "epoch: 185, current agent: v_, mean reward: 0.0024603194574310612\n",
            "epoch: 186, current agent: v_, mean reward: 0.00404773067954888\n",
            "epoch: 187, current agent: v_, mean reward: 0.005703172158519726\n",
            "epoch: 188, current agent: v_, mean reward: 0.007514471189196105\n",
            "epoch: 189, current agent: v_, mean reward: 0.009799887488808582\n",
            "epoch: 190, current agent: v_, mean reward: 0.012513500101209607\n",
            "epoch: 191, current agent: v_, mean reward: 0.015244119484293373\n",
            "epoch: 192, current agent: v_, mean reward: 0.018087490503705603\n",
            "epoch: 193, current agent: v_, mean reward: 0.021360147699189255\n",
            "epoch: 194, current agent: v_, mean reward: 0.024627975863643882\n",
            "epoch: 195, current agent: v_, mean reward: 0.0282288048813506\n",
            "epoch: 196, current agent: v_, mean reward: 0.031490489990748466\n",
            "epoch: 197, current agent: v_, mean reward: 0.035438325873852164\n",
            "epoch: 198, current agent: v_, mean reward: 0.03895788778165707\n",
            "epoch: 199, current agent: v_, mean reward: 0.04295470114372116\n",
            "\n",
            "\n",
            "\n",
            "--------------------TEST BEGIN--------------------\n",
            "\n",
            "epoch: 0, mean reward: 0.020479335371242996\n",
            "epoch: 1, mean reward: 0.03724667928050996\n",
            "epoch: 2, mean reward: 0.056478170879316225\n",
            "epoch: 3, mean reward: 0.07536585227777862\n",
            "epoch: 4, mean reward: 0.09818799174107935\n",
            "epoch: 5, mean reward: 0.12714067296493783\n",
            "epoch: 6, mean reward: 0.15687655686292915\n",
            "epoch: 7, mean reward: 0.20321407336174946\n",
            "epoch: 8, mean reward: 0.24933962088258813\n",
            "epoch: 9, mean reward: 0.28672061583188013\n",
            "epoch: 10, mean reward: 0.33663240158637575\n",
            "epoch: 11, mean reward: 0.3859988949165099\n",
            "epoch: 12, mean reward: 0.43470192242779065\n",
            "epoch: 13, mean reward: 0.4823337740569913\n",
            "epoch: 14, mean reward: 0.531425586335691\n",
            "epoch: 15, mean reward: 0.5873298065811651\n",
            "epoch: 16, mean reward: 0.6267314053881134\n",
            "epoch: 17, mean reward: 0.6777008947448288\n",
            "epoch: 18, mean reward: 0.7317675840103435\n",
            "epoch: 19, mean reward: 0.7658077105389751\n",
            "\n",
            "---------------------TEST END---------------------\n",
            "\n",
            "epoch: 200, current agent: u_, mean reward: 0.04642322014711884\n",
            "epoch: 201, current agent: u_, mean reward: 0.03963963841958157\n",
            "epoch: 202, current agent: u_, mean reward: 0.032119673010993305\n",
            "epoch: 203, current agent: u_, mean reward: 0.026603289320013167\n",
            "epoch: 204, current agent: u_, mean reward: 0.02113792123675151\n",
            "epoch: 205, current agent: u_, mean reward: 0.016103977535666617\n",
            "epoch: 206, current agent: u_, mean reward: 0.012447956621491224\n",
            "epoch: 207, current agent: u_, mean reward: 0.008931059417904579\n",
            "epoch: 208, current agent: u_, mean reward: 0.006594884416095628\n",
            "epoch: 209, current agent: u_, mean reward: 0.004264831913086793\n",
            "epoch: 210, current agent: u_, mean reward: 0.0024928915611710785\n",
            "epoch: 211, current agent: u_, mean reward: 0.0013101971866158132\n",
            "epoch: 212, current agent: u_, mean reward: 0.0006122869394253853\n",
            "epoch: 213, current agent: u_, mean reward: 0.00010548489802538936\n",
            "epoch: 214, current agent: u_, mean reward: 7.227196447256575e-05\n",
            "epoch: 215, current agent: u_, mean reward: 8.816812693252841e-05\n",
            "epoch: 216, current agent: u_, mean reward: 7.457143720630537e-05\n",
            "epoch: 217, current agent: u_, mean reward: 5.613814026909266e-05\n",
            "epoch: 218, current agent: u_, mean reward: 8.092131619043011e-05\n",
            "epoch: 219, current agent: u_, mean reward: 8.0692938194977e-05\n",
            "\n",
            "\n",
            "epoch: 220, current agent: v_, mean reward: 2.520746562567123e-05\n",
            "epoch: 221, current agent: v_, mean reward: 4.33047343146955e-05\n",
            "epoch: 222, current agent: v_, mean reward: 0.0001622558358976284\n",
            "epoch: 223, current agent: v_, mean reward: 0.0004144409079386857\n",
            "epoch: 224, current agent: v_, mean reward: 0.000770432839722201\n",
            "epoch: 225, current agent: v_, mean reward: 0.001202665962257346\n",
            "epoch: 226, current agent: v_, mean reward: 0.0017256496726439415\n",
            "epoch: 227, current agent: v_, mean reward: 0.0023271822028862197\n",
            "epoch: 228, current agent: v_, mean reward: 0.0029928420685584084\n",
            "epoch: 229, current agent: v_, mean reward: 0.0037386708181067043\n",
            "epoch: 230, current agent: v_, mean reward: 0.004563332784215794\n",
            "epoch: 231, current agent: v_, mean reward: 0.005488418806394616\n",
            "epoch: 232, current agent: v_, mean reward: 0.006393958500063034\n",
            "epoch: 233, current agent: v_, mean reward: 0.0076265721484708475\n",
            "epoch: 234, current agent: v_, mean reward: 0.008853496990874224\n",
            "epoch: 235, current agent: v_, mean reward: 0.01011250788035947\n",
            "epoch: 236, current agent: v_, mean reward: 0.011185852287348443\n",
            "epoch: 237, current agent: v_, mean reward: 0.012454190462859662\n",
            "epoch: 238, current agent: v_, mean reward: 0.013460826235404273\n",
            "epoch: 239, current agent: v_, mean reward: 0.014612346907949889\n",
            "\n",
            "\n",
            "epoch: 240, current agent: u_, mean reward: 0.015872703658837334\n",
            "epoch: 241, current agent: u_, mean reward: 0.013846090134015967\n",
            "epoch: 242, current agent: u_, mean reward: 0.011115409925156956\n",
            "epoch: 243, current agent: u_, mean reward: 0.008587129442958981\n",
            "epoch: 244, current agent: u_, mean reward: 0.0066193640056383864\n",
            "epoch: 245, current agent: u_, mean reward: 0.004718422850372269\n",
            "epoch: 246, current agent: u_, mean reward: 0.003277519492768317\n",
            "epoch: 247, current agent: u_, mean reward: 0.002067519537747661\n",
            "epoch: 248, current agent: u_, mean reward: 0.0012139658031516626\n",
            "epoch: 249, current agent: u_, mean reward: 0.0005102453513739021\n",
            "\n",
            "--------------------TEST BEGIN--------------------\n",
            "\n",
            "epoch: 0, mean reward: 0.005826320595905072\n",
            "epoch: 1, mean reward: 0.010931394048446166\n",
            "epoch: 2, mean reward: 0.016181881154984493\n",
            "epoch: 3, mean reward: 0.023034697031312685\n",
            "epoch: 4, mean reward: 0.032524809152013244\n",
            "epoch: 5, mean reward: 0.040699429700282216\n",
            "epoch: 6, mean reward: 0.04926350326394956\n",
            "epoch: 7, mean reward: 0.06394120925553387\n",
            "epoch: 8, mean reward: 0.08117835505878443\n",
            "epoch: 9, mean reward: 0.09543352511112455\n",
            "epoch: 10, mean reward: 0.11594260494189915\n",
            "epoch: 11, mean reward: 0.1416990862277469\n",
            "epoch: 12, mean reward: 0.167063849589413\n",
            "epoch: 13, mean reward: 0.19413817690304933\n",
            "epoch: 14, mean reward: 0.22416994808477025\n",
            "epoch: 15, mean reward: 0.25882638161673976\n",
            "epoch: 16, mean reward: 0.2855420583279575\n",
            "epoch: 17, mean reward: 0.3266903385705004\n",
            "epoch: 18, mean reward: 0.35692884542075487\n",
            "epoch: 19, mean reward: 0.4046142473901739\n",
            "\n",
            "---------------------TEST END---------------------\n",
            "\n",
            "epoch: 250, current agent: u_, mean reward: 0.0001756661816005874\n",
            "epoch: 251, current agent: u_, mean reward: 6.859708577755885e-05\n",
            "epoch: 252, current agent: u_, mean reward: 6.406363464539998e-05\n",
            "epoch: 253, current agent: u_, mean reward: 5.675335346840021e-05\n",
            "epoch: 254, current agent: u_, mean reward: 7.535926341495613e-05\n",
            "epoch: 255, current agent: u_, mean reward: 5.379995122322831e-05\n",
            "epoch: 256, current agent: u_, mean reward: 6.673613389332361e-05\n",
            "epoch: 257, current agent: u_, mean reward: 7.7699547665966e-05\n",
            "epoch: 258, current agent: u_, mean reward: 6.405405120996125e-05\n",
            "epoch: 259, current agent: u_, mean reward: 6.580374874284654e-05\n",
            "\n",
            "\n",
            "epoch: 260, current agent: v_, mean reward: 1.6968946585222275e-05\n",
            "epoch: 261, current agent: v_, mean reward: 2.3634899426897958e-05\n",
            "epoch: 262, current agent: v_, mean reward: 2.041642061351946e-05\n",
            "epoch: 263, current agent: v_, mean reward: 3.595391520563744e-05\n",
            "epoch: 264, current agent: v_, mean reward: 8.089398415826266e-05\n",
            "epoch: 265, current agent: v_, mean reward: 0.00018771839500556566\n",
            "epoch: 266, current agent: v_, mean reward: 0.0003286446181256617\n",
            "epoch: 267, current agent: v_, mean reward: 0.0005191396195221618\n",
            "epoch: 268, current agent: v_, mean reward: 0.0007250935496975465\n",
            "epoch: 269, current agent: v_, mean reward: 0.001002327931173423\n",
            "epoch: 270, current agent: v_, mean reward: 0.0013623104220243367\n",
            "epoch: 271, current agent: v_, mean reward: 0.0017946269255675168\n",
            "epoch: 272, current agent: v_, mean reward: 0.002156574908775513\n",
            "epoch: 273, current agent: v_, mean reward: 0.002607912673191786\n",
            "epoch: 274, current agent: v_, mean reward: 0.0030182612670490256\n",
            "epoch: 275, current agent: v_, mean reward: 0.0036030030791527725\n",
            "epoch: 276, current agent: v_, mean reward: 0.004101898876975023\n",
            "epoch: 277, current agent: v_, mean reward: 0.004671401521587857\n",
            "epoch: 278, current agent: v_, mean reward: 0.005331689012525734\n",
            "epoch: 279, current agent: v_, mean reward: 0.005972702100632138\n",
            "\n",
            "\n",
            "epoch: 280, current agent: u_, mean reward: 0.006792800678287369\n",
            "epoch: 281, current agent: u_, mean reward: 0.005411785875752437\n",
            "epoch: 282, current agent: u_, mean reward: 0.003973966645551034\n",
            "epoch: 283, current agent: u_, mean reward: 0.0027681717735475097\n",
            "epoch: 284, current agent: u_, mean reward: 0.0017258721078014885\n",
            "epoch: 285, current agent: u_, mean reward: 0.0010252788290208692\n",
            "epoch: 286, current agent: u_, mean reward: 0.0005084044987221714\n",
            "epoch: 287, current agent: u_, mean reward: 0.00016789296295974712\n",
            "epoch: 288, current agent: u_, mean reward: 8.511110939648776e-05\n",
            "epoch: 289, current agent: u_, mean reward: 7.606307160458404e-05\n",
            "epoch: 290, current agent: u_, mean reward: 6.824064778783559e-05\n",
            "epoch: 291, current agent: u_, mean reward: 6.308542290014766e-05\n",
            "epoch: 292, current agent: u_, mean reward: 6.74311139395671e-05\n",
            "epoch: 293, current agent: u_, mean reward: 7.06288932735094e-05\n",
            "epoch: 294, current agent: u_, mean reward: 7.536742701169006e-05\n",
            "epoch: 295, current agent: u_, mean reward: 7.040326641030087e-05\n",
            "epoch: 296, current agent: u_, mean reward: 5.466967243070394e-05\n",
            "epoch: 297, current agent: u_, mean reward: 6.1003300455739077e-05\n",
            "epoch: 298, current agent: u_, mean reward: 7.477058234004488e-05\n",
            "epoch: 299, current agent: u_, mean reward: 8.828602492547271e-05\n",
            "\n",
            "\n",
            "\n",
            "--------------------TEST BEGIN--------------------\n",
            "\n",
            "epoch: 0, mean reward: 0.008135844142116835\n",
            "epoch: 1, mean reward: 0.008916686891820768\n",
            "epoch: 2, mean reward: 0.010479098348478115\n",
            "epoch: 3, mean reward: 0.013431883666401039\n",
            "epoch: 4, mean reward: 0.018815291805316787\n",
            "epoch: 5, mean reward: 0.02503163955364504\n",
            "epoch: 6, mean reward: 0.030997437660671538\n",
            "epoch: 7, mean reward: 0.03349674167831707\n",
            "epoch: 8, mean reward: 0.04128719493862497\n",
            "epoch: 9, mean reward: 0.04786174578995893\n",
            "epoch: 10, mean reward: 0.05787286758792283\n",
            "epoch: 11, mean reward: 0.06322331668012263\n",
            "epoch: 12, mean reward: 0.06936708867380316\n",
            "epoch: 13, mean reward: 0.07414166583581397\n",
            "epoch: 14, mean reward: 0.08781180310714377\n",
            "epoch: 15, mean reward: 0.09396347974716086\n",
            "epoch: 16, mean reward: 0.10202898871250492\n",
            "epoch: 17, mean reward: 0.114202306548965\n",
            "epoch: 18, mean reward: 0.12488448685346182\n",
            "epoch: 19, mean reward: 0.13265225766841218\n",
            "\n",
            "---------------------TEST END---------------------\n",
            "\n",
            "epoch: 300, current agent: v_, mean reward: 1.2819137092609345e-05\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnAuA95963EE",
        "colab_type": "code",
        "outputId": "410c8e20-a3f5-47d2-f8a1-21df1c8df2ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "plot_mean_rewards(mean_rewards_one_by_one, method_name='fit one by one')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "348CMrbE5U5Y",
        "colab_type": "text"
      },
      "source": [
        "## Fit random pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZQDoMwYUcf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u_agents = [CCEMAgent((2,), (1,), percentile_param=30, action_max=env.u_action_max, reward_param=-1)\\\n",
        "            for _ in range(5)]\n",
        "v_agents = [CCEMAgent((2,), (1,), percentile_param=70, action_max=env.v_action_max, reward_param=1)\\\n",
        "            for _ in range(5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIqLynu7aDHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c372efe6-c9fe-434e-a119-f977f41ba73a"
      },
      "source": [
        "u_fit_random_agent, mean_rewards_random = fit_random_agent_pairs(u_agents, v_agents, env,\\\n",
        "                                                                 n_pairs=20, n_epochs=20, n_sessions=100, n_iter_debug=0)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------U_AGENT_1 VS V_AGENT_0--------------\n",
            "\n",
            "epoch: 0, mean reward: 5.395407871794628\n",
            "epoch: 1, mean reward: 4.751720269254389\n",
            "epoch: 2, mean reward: 4.177863807161329\n",
            "epoch: 3, mean reward: 3.6647508906614776\n",
            "epoch: 4, mean reward: 3.2472004795479665\n",
            "epoch: 5, mean reward: 2.8803140657726307\n",
            "epoch: 6, mean reward: 2.445676608189651\n",
            "epoch: 7, mean reward: 2.141482605631035\n",
            "epoch: 8, mean reward: 1.915194668136202\n",
            "epoch: 9, mean reward: 1.6608854641660273\n",
            "epoch: 10, mean reward: 1.4252524010206673\n",
            "epoch: 11, mean reward: 1.2236997366117084\n",
            "epoch: 12, mean reward: 0.9971516280470648\n",
            "epoch: 13, mean reward: 0.8818782631069553\n",
            "epoch: 14, mean reward: 0.7542736971299362\n",
            "epoch: 15, mean reward: 0.61632730742326\n",
            "epoch: 16, mean reward: 0.5326956100507938\n",
            "epoch: 17, mean reward: 0.4187103591283084\n",
            "epoch: 18, mean reward: 0.3437787655984964\n",
            "epoch: 19, mean reward: 0.2726083602565835\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_0 VS V_AGENT_0--------------\n",
            "\n",
            "epoch: 0, mean reward: 6.486117238301192\n",
            "epoch: 1, mean reward: 5.768543743410532\n",
            "epoch: 2, mean reward: 5.1390516826483585\n",
            "epoch: 3, mean reward: 4.707784973050584\n",
            "epoch: 4, mean reward: 4.242410703200209\n",
            "epoch: 5, mean reward: 3.8306073810017023\n",
            "epoch: 6, mean reward: 3.484204002374105\n",
            "epoch: 7, mean reward: 3.1267551315100888\n",
            "epoch: 8, mean reward: 2.8882589051112446\n",
            "epoch: 9, mean reward: 2.605207634896139\n",
            "epoch: 10, mean reward: 2.33783138438564\n",
            "epoch: 11, mean reward: 2.1528920650029164\n",
            "epoch: 12, mean reward: 1.9371828820045267\n",
            "epoch: 13, mean reward: 1.7423807004389469\n",
            "epoch: 14, mean reward: 1.5247379940081995\n",
            "epoch: 15, mean reward: 1.4065022780350975\n",
            "epoch: 16, mean reward: 1.2624869680177861\n",
            "epoch: 17, mean reward: 1.1934150219644457\n",
            "epoch: 18, mean reward: 1.1004489474856607\n",
            "epoch: 19, mean reward: 0.9853031275377379\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_0 VS V_AGENT_2--------------\n",
            "\n",
            "epoch: 0, mean reward: 0.10542581333187233\n",
            "epoch: 1, mean reward: 0.0940789329493977\n",
            "epoch: 2, mean reward: 0.08631084118448375\n",
            "epoch: 3, mean reward: 0.07385637876551607\n",
            "epoch: 4, mean reward: 0.06923944203594878\n",
            "epoch: 5, mean reward: 0.049546278508976915\n",
            "epoch: 6, mean reward: 0.045325758758746754\n",
            "epoch: 7, mean reward: 0.034516308913423985\n",
            "epoch: 8, mean reward: 0.023456151657276613\n",
            "epoch: 9, mean reward: 0.012914246961654545\n",
            "epoch: 10, mean reward: 0.009884486471617094\n",
            "epoch: 11, mean reward: 0.00826559057895621\n",
            "epoch: 12, mean reward: 0.00512926537866038\n",
            "epoch: 13, mean reward: 0.0026720276166900003\n",
            "epoch: 14, mean reward: 0.0025607555835613625\n",
            "epoch: 15, mean reward: 0.0021807740075652253\n",
            "epoch: 16, mean reward: 0.003209435088509226\n",
            "epoch: 17, mean reward: 0.0027242633415374778\n",
            "epoch: 18, mean reward: 0.0027144379726747486\n",
            "epoch: 19, mean reward: 0.0031365713002695413\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_0 VS V_AGENT_2--------------\n",
            "\n",
            "epoch: 0, mean reward: 0.0022975038311360677\n",
            "epoch: 1, mean reward: 0.0021127762353821463\n",
            "epoch: 2, mean reward: 0.002997732997559718\n",
            "epoch: 3, mean reward: 0.002671461075694853\n",
            "epoch: 4, mean reward: 0.002510035855433785\n",
            "epoch: 5, mean reward: 0.0017386901375938785\n",
            "epoch: 6, mean reward: 0.0020487918851633067\n",
            "epoch: 7, mean reward: 0.0021765714202433457\n",
            "epoch: 8, mean reward: 0.0021443318543892275\n",
            "epoch: 9, mean reward: 0.0019065630677347818\n",
            "epoch: 10, mean reward: 0.0026546379595953217\n",
            "epoch: 11, mean reward: 0.0021091914926480372\n",
            "epoch: 12, mean reward: 0.0018424326855682202\n",
            "epoch: 13, mean reward: 0.001335659973462177\n",
            "epoch: 14, mean reward: 0.0015372731957667832\n",
            "epoch: 15, mean reward: 0.001251871466345636\n",
            "epoch: 16, mean reward: 0.0013664374040413755\n",
            "epoch: 17, mean reward: 0.001451064430511634\n",
            "epoch: 18, mean reward: 0.0010923296395433635\n",
            "epoch: 19, mean reward: 0.001352509054688193\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_2 VS V_AGENT_2--------------\n",
            "\n",
            "epoch: 0, mean reward: 3.49107881723141\n",
            "epoch: 1, mean reward: 2.945919136709028\n",
            "epoch: 2, mean reward: 2.494446057427959\n",
            "epoch: 3, mean reward: 2.1163407097785596\n",
            "epoch: 4, mean reward: 1.7583209831871338\n",
            "epoch: 5, mean reward: 1.4484040124917816\n",
            "epoch: 6, mean reward: 1.1741848408902424\n",
            "epoch: 7, mean reward: 0.9552749780434506\n",
            "epoch: 8, mean reward: 0.7796004921144969\n",
            "epoch: 9, mean reward: 0.5929123702484143\n",
            "epoch: 10, mean reward: 0.4483394219134095\n",
            "epoch: 11, mean reward: 0.3657824708059449\n",
            "epoch: 12, mean reward: 0.2918175690986793\n",
            "epoch: 13, mean reward: 0.24549955477963717\n",
            "epoch: 14, mean reward: 0.18407676870807355\n",
            "epoch: 15, mean reward: 0.13328820708868558\n",
            "epoch: 16, mean reward: 0.10069269628656247\n",
            "epoch: 17, mean reward: 0.06919597484337169\n",
            "epoch: 18, mean reward: 0.039694436565714614\n",
            "epoch: 19, mean reward: 0.024631954034688514\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_3 VS V_AGENT_0--------------\n",
            "\n",
            "epoch: 0, mean reward: 5.255905513455587\n",
            "epoch: 1, mean reward: 4.780192625547735\n",
            "epoch: 2, mean reward: 4.3047180384920685\n",
            "epoch: 3, mean reward: 3.667941827390398\n",
            "epoch: 4, mean reward: 3.117590702864007\n",
            "epoch: 5, mean reward: 2.5453307924021322\n",
            "epoch: 6, mean reward: 2.127379442548325\n",
            "epoch: 7, mean reward: 1.7929025898664444\n",
            "epoch: 8, mean reward: 1.5796602276840719\n",
            "epoch: 9, mean reward: 1.3185598225461808\n",
            "epoch: 10, mean reward: 1.1255730133357658\n",
            "epoch: 11, mean reward: 0.960939656082182\n",
            "epoch: 12, mean reward: 0.8308752198239816\n",
            "epoch: 13, mean reward: 0.6925862790217462\n",
            "epoch: 14, mean reward: 0.5954990510671755\n",
            "epoch: 15, mean reward: 0.4880186255795159\n",
            "epoch: 16, mean reward: 0.4004031833813824\n",
            "epoch: 17, mean reward: 0.3247531824627454\n",
            "epoch: 18, mean reward: 0.27292553122664454\n",
            "epoch: 19, mean reward: 0.2151148980800513\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_0 VS V_AGENT_2--------------\n",
            "\n",
            "epoch: 0, mean reward: 0.006285409628574709\n",
            "epoch: 1, mean reward: 0.00300005958939759\n",
            "epoch: 2, mean reward: 0.0015654231809398458\n",
            "epoch: 3, mean reward: 0.0011834670418840259\n",
            "epoch: 4, mean reward: 0.0008565433230739311\n",
            "epoch: 5, mean reward: 0.0007535243518060181\n",
            "epoch: 6, mean reward: 0.0007343406296808245\n",
            "epoch: 7, mean reward: 0.0005920441800125108\n",
            "epoch: 8, mean reward: 0.0005857174012272528\n",
            "epoch: 9, mean reward: 0.0005956345319198862\n",
            "epoch: 10, mean reward: 0.0006532659208141066\n",
            "epoch: 11, mean reward: 0.000653821267738902\n",
            "epoch: 12, mean reward: 0.0005683552610038975\n",
            "epoch: 13, mean reward: 0.000588133768326959\n",
            "epoch: 14, mean reward: 0.0005071352789489572\n",
            "epoch: 15, mean reward: 0.00046728841819584655\n",
            "epoch: 16, mean reward: 0.00040016259996165877\n",
            "epoch: 17, mean reward: 0.0003696430918307059\n",
            "epoch: 18, mean reward: 0.0003318952899904039\n",
            "epoch: 19, mean reward: 0.0004825143875664483\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_3 VS V_AGENT_1--------------\n",
            "\n",
            "epoch: 0, mean reward: 0.7394612909910384\n",
            "epoch: 1, mean reward: 0.6737445553637174\n",
            "epoch: 2, mean reward: 0.5808905126694424\n",
            "epoch: 3, mean reward: 0.5213774771456192\n",
            "epoch: 4, mean reward: 0.45613562747064706\n",
            "epoch: 5, mean reward: 0.41005685704582895\n",
            "epoch: 6, mean reward: 0.35938280375768455\n",
            "epoch: 7, mean reward: 0.3230294656292236\n",
            "epoch: 8, mean reward: 0.2882914759573402\n",
            "epoch: 9, mean reward: 0.2533205174944932\n",
            "epoch: 10, mean reward: 0.2167846957691487\n",
            "epoch: 11, mean reward: 0.18057110138063376\n",
            "epoch: 12, mean reward: 0.14734201186196194\n",
            "epoch: 13, mean reward: 0.11753209888464604\n",
            "epoch: 14, mean reward: 0.099054492903414\n",
            "epoch: 15, mean reward: 0.08150217547644852\n",
            "epoch: 16, mean reward: 0.07380114601676376\n",
            "epoch: 17, mean reward: 0.051086453931102546\n",
            "epoch: 18, mean reward: 0.03613748335219693\n",
            "epoch: 19, mean reward: 0.02387777644141761\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_3 VS V_AGENT_2--------------\n",
            "\n",
            "epoch: 0, mean reward: 1.5221718982394228\n",
            "epoch: 1, mean reward: 1.381405715985208\n",
            "epoch: 2, mean reward: 1.2508347183740296\n",
            "epoch: 3, mean reward: 1.1300770646962115\n",
            "epoch: 4, mean reward: 1.0276463614738474\n",
            "epoch: 5, mean reward: 0.9350871426041634\n",
            "epoch: 6, mean reward: 0.8332280911143607\n",
            "epoch: 7, mean reward: 0.7513576440148699\n",
            "epoch: 8, mean reward: 0.6813420627603225\n",
            "epoch: 9, mean reward: 0.6155127432092395\n",
            "epoch: 10, mean reward: 0.5519500523898531\n",
            "epoch: 11, mean reward: 0.49082049988846926\n",
            "epoch: 12, mean reward: 0.4290765253829133\n",
            "epoch: 13, mean reward: 0.3720673019587024\n",
            "epoch: 14, mean reward: 0.3311652658783859\n",
            "epoch: 15, mean reward: 0.2892293323264142\n",
            "epoch: 16, mean reward: 0.24819417246243008\n",
            "epoch: 17, mean reward: 0.20869793370935136\n",
            "epoch: 18, mean reward: 0.1802279115762603\n",
            "epoch: 19, mean reward: 0.14858179374209957\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_3 VS V_AGENT_2--------------\n",
            "\n",
            "epoch: 0, mean reward: 0.1220159935996799\n",
            "epoch: 1, mean reward: 0.09877187439648483\n",
            "epoch: 2, mean reward: 0.07742080134228717\n",
            "epoch: 3, mean reward: 0.06379116332089754\n",
            "epoch: 4, mean reward: 0.052041493997652184\n",
            "epoch: 5, mean reward: 0.04047520161335588\n",
            "epoch: 6, mean reward: 0.02933894362390929\n",
            "epoch: 7, mean reward: 0.021191446003656744\n",
            "epoch: 8, mean reward: 0.013985146808427851\n",
            "epoch: 9, mean reward: 0.008309282743866076\n",
            "epoch: 10, mean reward: 0.004338424099982143\n",
            "epoch: 11, mean reward: 0.0017561719284399397\n",
            "epoch: 12, mean reward: 0.0003693902972232292\n",
            "epoch: 13, mean reward: 0.0003493573829017679\n",
            "epoch: 14, mean reward: 0.0002329431702693027\n",
            "epoch: 15, mean reward: 0.00029100896508786335\n",
            "epoch: 16, mean reward: 0.0003313064235144147\n",
            "epoch: 17, mean reward: 0.00026912967989435556\n",
            "epoch: 18, mean reward: 0.0002311672830140182\n",
            "epoch: 19, mean reward: 0.00029846628299205134\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_2 VS V_AGENT_0--------------\n",
            "\n",
            "epoch: 0, mean reward: 0.12642156877538674\n",
            "epoch: 1, mean reward: 0.09021200488644686\n",
            "epoch: 2, mean reward: 0.06621630193847385\n",
            "epoch: 3, mean reward: 0.03930970583957645\n",
            "epoch: 4, mean reward: 0.027667771023840704\n",
            "epoch: 5, mean reward: 0.02002151680463106\n",
            "epoch: 6, mean reward: 0.011379786619823742\n",
            "epoch: 7, mean reward: 0.00803204925177978\n",
            "epoch: 8, mean reward: 0.004334826830992052\n",
            "epoch: 9, mean reward: 0.004563650549400607\n",
            "epoch: 10, mean reward: 0.002869689168867806\n",
            "epoch: 11, mean reward: 0.0039046633673993155\n",
            "epoch: 12, mean reward: 0.0033401344584950495\n",
            "epoch: 13, mean reward: 0.0023168080501119563\n",
            "epoch: 14, mean reward: 0.002121405211766098\n",
            "epoch: 15, mean reward: 0.0019177841780473436\n",
            "epoch: 16, mean reward: 0.0016714266559401745\n",
            "epoch: 17, mean reward: 0.0019145315332199356\n",
            "epoch: 18, mean reward: 0.0018386888201575504\n",
            "epoch: 19, mean reward: 0.0013683154358081961\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_0 VS V_AGENT_2--------------\n",
            "\n",
            "epoch: 0, mean reward: 0.0016446261058912246\n",
            "epoch: 1, mean reward: 0.0004956135542735076\n",
            "epoch: 2, mean reward: 0.000313488332794075\n",
            "epoch: 3, mean reward: 0.0004041721901884715\n",
            "epoch: 4, mean reward: 0.0003545567483165032\n",
            "epoch: 5, mean reward: 0.0002451947353464423\n",
            "epoch: 6, mean reward: 0.0002633826502694574\n",
            "epoch: 7, mean reward: 0.00024305750108386407\n",
            "epoch: 8, mean reward: 0.00025569811395172463\n",
            "epoch: 9, mean reward: 0.000269211625738177\n",
            "epoch: 10, mean reward: 0.000198767381787775\n",
            "epoch: 11, mean reward: 0.0002330338772935833\n",
            "epoch: 12, mean reward: 0.00026967111680397635\n",
            "epoch: 13, mean reward: 0.00021367037277181809\n",
            "epoch: 14, mean reward: 0.00023291194656133624\n",
            "epoch: 15, mean reward: 0.00023619769045380378\n",
            "epoch: 16, mean reward: 0.00019564133178602656\n",
            "epoch: 17, mean reward: 0.00018338170816726532\n",
            "epoch: 18, mean reward: 0.0001599791526722204\n",
            "epoch: 19, mean reward: 0.0001590861529726196\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_1 VS V_AGENT_0--------------\n",
            "\n",
            "epoch: 0, mean reward: 0.7844446804736939\n",
            "epoch: 1, mean reward: 0.6381194223509776\n",
            "epoch: 2, mean reward: 0.5329538985929859\n",
            "epoch: 3, mean reward: 0.42053196139842547\n",
            "epoch: 4, mean reward: 0.3494692632335088\n",
            "epoch: 5, mean reward: 0.2756924234419629\n",
            "epoch: 6, mean reward: 0.20818064988651322\n",
            "epoch: 7, mean reward: 0.153207556534053\n",
            "epoch: 8, mean reward: 0.10391671818237697\n",
            "epoch: 9, mean reward: 0.06365763545266911\n",
            "epoch: 10, mean reward: 0.03941975639049867\n",
            "epoch: 11, mean reward: 0.020085423550428777\n",
            "epoch: 12, mean reward: 0.009625310525401293\n",
            "epoch: 13, mean reward: 0.003179247524435424\n",
            "epoch: 14, mean reward: 0.0018947627807198825\n",
            "epoch: 15, mean reward: 0.0020269077533163157\n",
            "epoch: 16, mean reward: 0.0022739931442917927\n",
            "epoch: 17, mean reward: 0.002628079766822282\n",
            "epoch: 18, mean reward: 0.0013630115072530416\n",
            "epoch: 19, mean reward: 0.001494270367360949\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_0 VS V_AGENT_3--------------\n",
            "\n",
            "epoch: 0, mean reward: 0.7106953667284046\n",
            "epoch: 1, mean reward: 0.7782952750564129\n",
            "epoch: 2, mean reward: 0.8452283806263226\n",
            "epoch: 3, mean reward: 0.9238124247551801\n",
            "epoch: 4, mean reward: 1.0289424084079797\n",
            "epoch: 5, mean reward: 1.111426505412637\n",
            "epoch: 6, mean reward: 1.1901283740209663\n",
            "epoch: 7, mean reward: 1.3004109975414013\n",
            "epoch: 8, mean reward: 1.3818225188962185\n",
            "epoch: 9, mean reward: 1.4789013287425652\n",
            "epoch: 10, mean reward: 1.5785263377895327\n",
            "epoch: 11, mean reward: 1.6638572469486652\n",
            "epoch: 12, mean reward: 1.7436744316553328\n",
            "epoch: 13, mean reward: 1.8021649019064214\n",
            "epoch: 14, mean reward: 1.8699723086181643\n",
            "epoch: 15, mean reward: 1.9387217436780546\n",
            "epoch: 16, mean reward: 1.9949912385237212\n",
            "epoch: 17, mean reward: 2.056581952746032\n",
            "epoch: 18, mean reward: 2.114830812167863\n",
            "epoch: 19, mean reward: 2.1737526876311626\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_1 VS V_AGENT_0--------------\n",
            "\n",
            "epoch: 0, mean reward: 0.0013679251531532304\n",
            "epoch: 1, mean reward: 0.001553340619744956\n",
            "epoch: 2, mean reward: 0.0015427090272000716\n",
            "epoch: 3, mean reward: 0.0013147426470880733\n",
            "epoch: 4, mean reward: 0.0014186832464108145\n",
            "epoch: 5, mean reward: 0.0013904740389854998\n",
            "epoch: 6, mean reward: 0.0015911379178131014\n",
            "epoch: 7, mean reward: 0.0010399901372925746\n",
            "epoch: 8, mean reward: 0.0009703114758352243\n",
            "epoch: 9, mean reward: 0.0012787342268762126\n",
            "epoch: 10, mean reward: 0.0009845637576428084\n",
            "epoch: 11, mean reward: 0.0012427259656294747\n",
            "epoch: 12, mean reward: 0.0008515210498205284\n",
            "epoch: 13, mean reward: 0.0009588596673451372\n",
            "epoch: 14, mean reward: 0.0008942307245087372\n",
            "epoch: 15, mean reward: 0.0010058071556976454\n",
            "epoch: 16, mean reward: 0.0008414703458816101\n",
            "epoch: 17, mean reward: 0.0007591044083138233\n",
            "epoch: 18, mean reward: 0.000678018457608414\n",
            "epoch: 19, mean reward: 0.0006635021150909049\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_4 VS V_AGENT_4--------------\n",
            "\n",
            "epoch: 0, mean reward: 4.824579232693347\n",
            "epoch: 1, mean reward: 4.4275525561389655\n",
            "epoch: 2, mean reward: 4.282858561048325\n",
            "epoch: 3, mean reward: 4.050281494341112\n",
            "epoch: 4, mean reward: 3.9308510415912026\n",
            "epoch: 5, mean reward: 3.5888496840347592\n",
            "epoch: 6, mean reward: 3.344973890304995\n",
            "epoch: 7, mean reward: 3.0989438254241195\n",
            "epoch: 8, mean reward: 2.8947542161728\n",
            "epoch: 9, mean reward: 2.7979878750445346\n",
            "epoch: 10, mean reward: 2.570399730361871\n",
            "epoch: 11, mean reward: 2.389434007272022\n",
            "epoch: 12, mean reward: 2.283884066807068\n",
            "epoch: 13, mean reward: 2.1341182486722348\n",
            "epoch: 14, mean reward: 2.000153440411459\n",
            "epoch: 15, mean reward: 1.9091907889623527\n",
            "epoch: 16, mean reward: 1.7518602982550533\n",
            "epoch: 17, mean reward: 1.6213587500457125\n",
            "epoch: 18, mean reward: 1.4829497227599322\n",
            "epoch: 19, mean reward: 1.4081401942436182\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_2 VS V_AGENT_4--------------\n",
            "\n",
            "epoch: 0, mean reward: 0.20433911838412647\n",
            "epoch: 1, mean reward: 0.17317501832041604\n",
            "epoch: 2, mean reward: 0.1569421426613825\n",
            "epoch: 3, mean reward: 0.1403301800105624\n",
            "epoch: 4, mean reward: 0.12225998562260729\n",
            "epoch: 5, mean reward: 0.10056382360219551\n",
            "epoch: 6, mean reward: 0.07647589353197935\n",
            "epoch: 7, mean reward: 0.06558021477784721\n",
            "epoch: 8, mean reward: 0.04982597532498548\n",
            "epoch: 9, mean reward: 0.043875566001744574\n",
            "epoch: 10, mean reward: 0.03360551785855068\n",
            "epoch: 11, mean reward: 0.026028701367212873\n",
            "epoch: 12, mean reward: 0.022980336153693527\n",
            "epoch: 13, mean reward: 0.018310938696722574\n",
            "epoch: 14, mean reward: 0.01361536459770687\n",
            "epoch: 15, mean reward: 0.008317649013961594\n",
            "epoch: 16, mean reward: 0.0048986711552599545\n",
            "epoch: 17, mean reward: 0.003790182244282627\n",
            "epoch: 18, mean reward: 0.0019385455009651405\n",
            "epoch: 19, mean reward: 0.0018187726091172883\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_0 VS V_AGENT_0--------------\n",
            "\n",
            "epoch: 0, mean reward: 0.04820690699652654\n",
            "epoch: 1, mean reward: 0.042544180533954784\n",
            "epoch: 2, mean reward: 0.038798877174423436\n",
            "epoch: 3, mean reward: 0.03387394478614895\n",
            "epoch: 4, mean reward: 0.02985086277499806\n",
            "epoch: 5, mean reward: 0.026591017207652553\n",
            "epoch: 6, mean reward: 0.02443406877772629\n",
            "epoch: 7, mean reward: 0.020770120296849548\n",
            "epoch: 8, mean reward: 0.018461798721424446\n",
            "epoch: 9, mean reward: 0.01560553664147212\n",
            "epoch: 10, mean reward: 0.012988066231670134\n",
            "epoch: 11, mean reward: 0.010359108058961336\n",
            "epoch: 12, mean reward: 0.007393604329839566\n",
            "epoch: 13, mean reward: 0.0055206203779672915\n",
            "epoch: 14, mean reward: 0.003994325615500557\n",
            "epoch: 15, mean reward: 0.002880755986058506\n",
            "epoch: 16, mean reward: 0.002009970852446767\n",
            "epoch: 17, mean reward: 0.0013029723731346379\n",
            "epoch: 18, mean reward: 0.0006125504595413215\n",
            "epoch: 19, mean reward: 0.00017611063065227177\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_2 VS V_AGENT_0--------------\n",
            "\n",
            "epoch: 0, mean reward: 0.778253455424379\n",
            "epoch: 1, mean reward: 0.7169839847353857\n",
            "epoch: 2, mean reward: 0.653536407260966\n",
            "epoch: 3, mean reward: 0.6065967578106809\n",
            "epoch: 4, mean reward: 0.5458531686729103\n",
            "epoch: 5, mean reward: 0.4930190757837487\n",
            "epoch: 6, mean reward: 0.4448955392103251\n",
            "epoch: 7, mean reward: 0.4041376373540115\n",
            "epoch: 8, mean reward: 0.3634414686562183\n",
            "epoch: 9, mean reward: 0.32555497732306476\n",
            "epoch: 10, mean reward: 0.29496717417572504\n",
            "epoch: 11, mean reward: 0.25929465453964906\n",
            "epoch: 12, mean reward: 0.22707164545114583\n",
            "epoch: 13, mean reward: 0.20052347331109757\n",
            "epoch: 14, mean reward: 0.17159424758685884\n",
            "epoch: 15, mean reward: 0.1488251800057788\n",
            "epoch: 16, mean reward: 0.12986607319544533\n",
            "epoch: 17, mean reward: 0.11355156544090801\n",
            "epoch: 18, mean reward: 0.09557065900463585\n",
            "epoch: 19, mean reward: 0.08205325929150588\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "--------------U_AGENT_0 VS V_AGENT_3--------------\n",
            "\n",
            "epoch: 0, mean reward: 3.2698143611001256\n",
            "epoch: 1, mean reward: 3.3057748473547806\n",
            "epoch: 2, mean reward: 3.3927469313970415\n",
            "epoch: 3, mean reward: 3.4708323263347456\n",
            "epoch: 4, mean reward: 3.538758671879632\n",
            "epoch: 5, mean reward: 3.630261299609559\n",
            "epoch: 6, mean reward: 3.6798439744781892\n",
            "epoch: 7, mean reward: 3.7394435715669783\n",
            "epoch: 8, mean reward: 3.783264746968971\n",
            "epoch: 9, mean reward: 3.8783231324558836\n",
            "epoch: 10, mean reward: 3.937896549497166\n",
            "epoch: 11, mean reward: 4.014806501239363\n",
            "epoch: 12, mean reward: 4.0756971666458925\n",
            "epoch: 13, mean reward: 4.14580573533011\n",
            "epoch: 14, mean reward: 4.200358772043181\n",
            "epoch: 15, mean reward: 4.23915833708808\n",
            "epoch: 16, mean reward: 4.2855511477780945\n",
            "epoch: 17, mean reward: 4.338777139672207\n",
            "epoch: 18, mean reward: 4.373504092343905\n",
            "epoch: 19, mean reward: 4.433077284075347\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Best agent is 0, its best reward is 0.0001590861529726196\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9PYm_lX2h-H",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrkkxFDSJ1Sn",
        "colab_type": "text"
      },
      "source": [
        "## Test default u_agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzC4Sb2QJ1Sq",
        "colab_type": "code",
        "outputId": "1eb3ce44-00c8-4c69-9754-d85d811f3c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "test_rewards = test_agent(u_fit_agent, env, n_epochs=50, n_sessions=100, epsilon=-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, mean reward: 0.003540376363573217\n",
            "epoch: 1, mean reward: 0.003854413225272795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-006aded099fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_fit_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-03b805a2d825>\u001b[0m in \u001b[0;36mtest_agent\u001b[0;34m(u_agent, env, n_epochs, n_sessions, epsilon)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mv_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCCEMAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_action_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfit_agents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-82c2f8c5053f>\u001b[0m in \u001b[0;36mfit_agents\u001b[0;34m(u_agent, v_agent, env, n_epochs, n_sessions, epsilon, test, n_iter_debug)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{:-^50}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TEST END'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mmean_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch: {epoch}, mean reward: {mean_reward}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-5c22a553b5c6>\u001b[0m in \u001b[0;36mfit_epoch\u001b[0;34m(u_agent, v_agent, env, n_sessions, test)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_reward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-5c22a553b5c6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_reward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-5c22a553b5c6>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(u_agent, v_agent, env, test)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mu_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mv_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'u_'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ca55eef9851f>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state, test)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_threshold\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mpredicted_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_action\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredicted_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mclip\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mclip\u001b[0;34m(a, a_min, a_max, out, **kwargs)\u001b[0m\n\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m     \"\"\"\n\u001b[0;32m-> 2084\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_clip\u001b[0;34m(a, min, max, out, casting, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_clip_dep_is_byte_swapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_clip_dep_is_byte_swapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0musing_deprecated_nan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0m_clip_dep_is_scalar_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0musing_deprecated_nan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_clip_dep_is_scalar_nan\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_clip_dep_is_scalar_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# guarded to protect circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromnumeric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7ZITn34J1Ss",
        "colab_type": "code",
        "outputId": "e0ef7f04-d64f-484f-a2fc-b59bb844e574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plot_mean_rewards(test_rewards, method_name='test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aR-GlF-f0Yg",
        "colab_type": "text"
      },
      "source": [
        "## Test u_agent_one_by_one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZorei8v7Np4",
        "colab_type": "code",
        "outputId": "b9829018-8aab-4c23-d838-10b670cab9eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "test_rewards_one_by_one = test_agent(u_fit_agent_one_by_one, env, n_epochs=50, n_sessions=100, epsilon=1e-6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, mean reward: 1.8904017970650102\n",
            "epoch: 1, mean reward: 2.0885442948180923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-36247514d93f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_rewards_one_by_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_fit_agent_one_by_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-03b805a2d825>\u001b[0m in \u001b[0;36mtest_agent\u001b[0;34m(u_agent, env, n_epochs, n_sessions, epsilon)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mv_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCCEMAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_action_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfit_agents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-0f9940d9183e>\u001b[0m in \u001b[0;36mfit_agents\u001b[0;34m(u_agent, v_agent, env, n_epochs, n_sessions, epsilon, test, n_iter_debug)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n{:-^50}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TEST END'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mmean_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch: {epoch}, mean reward: {mean_reward}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-5c22a553b5c6>\u001b[0m in \u001b[0;36mfit_epoch\u001b[0;34m(u_agent, v_agent, env, n_sessions, test)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_reward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-5c22a553b5c6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_reward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-5c22a553b5c6>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(u_agent, v_agent, env, test)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mu_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mv_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_agent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'u_'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ca55eef9851f>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state, test)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mpredicted_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_threshold\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXK3jgOj7QN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_mean_rewards(test_rewards_one_by_one, method_name='test one by one')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X50sgCCUef2",
        "colab_type": "text"
      },
      "source": [
        "## Test u_agent_random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu2e5hPZUg9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "0a0358a5-68a6-4e25-a0bd-6dfcb7e0ed8e"
      },
      "source": [
        "test_rewards_random = test_agent(u_fit_random_agent, env, n_epochs=50, n_sessions=100, epsilon=1e-6)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, mean reward: 1.528297492605777\n",
            "epoch: 1, mean reward: 1.6296178719130816\n",
            "epoch: 2, mean reward: 1.7326942654073048\n",
            "epoch: 3, mean reward: 1.8258626555106798\n",
            "epoch: 4, mean reward: 1.898074342931412\n",
            "epoch: 5, mean reward: 1.9778876034830262\n",
            "epoch: 6, mean reward: 2.0721495362563886\n",
            "epoch: 7, mean reward: 2.165068378471574\n",
            "epoch: 8, mean reward: 2.248747824301549\n",
            "epoch: 9, mean reward: 2.333047099675407\n",
            "epoch: 10, mean reward: 2.420131887761807\n",
            "epoch: 11, mean reward: 2.4838559782290517\n",
            "epoch: 12, mean reward: 2.5846076565757308\n",
            "epoch: 13, mean reward: 2.671670035161762\n",
            "epoch: 14, mean reward: 2.763282630870746\n",
            "epoch: 15, mean reward: 2.840075122924543\n",
            "epoch: 16, mean reward: 2.923463620247993\n",
            "epoch: 17, mean reward: 2.996802678408969\n",
            "epoch: 18, mean reward: 3.0956656598813326\n",
            "epoch: 19, mean reward: 3.178412443594399\n",
            "epoch: 20, mean reward: 3.2539623248948546\n",
            "epoch: 21, mean reward: 3.287516654584037\n",
            "epoch: 22, mean reward: 3.3811910365146924\n",
            "epoch: 23, mean reward: 3.43992520304739\n",
            "epoch: 24, mean reward: 3.496933977061557\n",
            "epoch: 25, mean reward: 3.5505169283607576\n",
            "epoch: 26, mean reward: 3.628025062112932\n",
            "epoch: 27, mean reward: 3.6940902521291274\n",
            "epoch: 28, mean reward: 3.7542226741892524\n",
            "epoch: 29, mean reward: 3.7956992529306346\n",
            "epoch: 30, mean reward: 3.8415592018691904\n",
            "epoch: 31, mean reward: 3.8879376026669137\n",
            "epoch: 32, mean reward: 3.9502642350477313\n",
            "epoch: 33, mean reward: 3.9888684492578568\n",
            "epoch: 34, mean reward: 4.04248567016265\n",
            "epoch: 35, mean reward: 4.127969185749098\n",
            "epoch: 36, mean reward: 4.1865736179310895\n",
            "epoch: 37, mean reward: 4.2579024000319405\n",
            "epoch: 38, mean reward: 4.321850350508132\n",
            "epoch: 39, mean reward: 4.3971280866968945\n",
            "epoch: 40, mean reward: 4.443494499273234\n",
            "epoch: 41, mean reward: 4.48028127278928\n",
            "epoch: 42, mean reward: 4.543635561584256\n",
            "epoch: 43, mean reward: 4.598182949681252\n",
            "epoch: 44, mean reward: 4.642203025887327\n",
            "epoch: 45, mean reward: 4.669801181218355\n",
            "epoch: 46, mean reward: 4.7367231983452065\n",
            "epoch: 47, mean reward: 4.790653464046791\n",
            "epoch: 48, mean reward: 4.866872925594256\n",
            "epoch: 49, mean reward: 4.914837986130821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36jJd-5Hflhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_mean_rewards(test_rewards_random, method_name='test random pairs')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}